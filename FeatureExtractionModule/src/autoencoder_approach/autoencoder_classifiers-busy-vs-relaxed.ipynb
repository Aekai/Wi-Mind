{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers - busy vs relaxed\n",
    "Exploring different classifiers with different autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of contents:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoders:  \n",
    "[Undercomplete Autoencoder](#Undercomplete-Autoencoder)  \n",
    "[Sparse Autoencoder](#Sparse-Autoencoder)  \n",
    "[Deep Autoencoder](#Deep-Autoencoder)  \n",
    "[Contractive Autoencoder](#Contractive-Autoencoder)  \n",
    "\n",
    "classifiers:  \n",
    "[Simple dense layer](#Simple-dense-layer)  \n",
    "[LSTM-based classifier](#LSTM-based-classifier)  \n",
    "[kNN](#kNN)  \n",
    "[SVC](#SVC)  \n",
    "[Random Forest](#Random-Forest)  \n",
    "[XGBoost](#XGBoost)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datareader # made by the previous author for reading the collected data\n",
    "import dataextractor # same as above\n",
    "import pandas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# need to disable eager execution for .get_weights() in contractive autoencoder loss to work\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "# required for the contractive autoencoder\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "\n",
    "import talos\n",
    "from talos.utils import lr_normalizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.set_floatx('float32') # call this, to set keras to use float32 to avoid a warning message\n",
    "metrics = ['accuracy']#,\n",
    "#            keras.metrics.TruePositives(),\n",
    "#            keras.metrics.FalsePositives(),\n",
    "#            keras.metrics.TrueNegatives(),\n",
    "#            keras.metrics.FalseNegatives()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/ageron/handson-ml/blob/master/extra_tensorflow_reproducibility.ipynb\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                        inter_op_parallelism_threads=1)\n",
    "\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    #... this will run single threaded\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(4)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the notebook in the terminal with \"PYTHONHASHSEED=0 jupyter notebook\" \n",
    "# or in anaconda \"set PYTHONHASHSEED=0\" then start jupyter notebook\n",
    "import os\n",
    "if os.environ.get(\"PYTHONHASHSEED\") != \"0\":\n",
    "    raise Exception(\"You must set PYTHONHASHSEED=0 when starting the Jupyter server to get reproducible results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is modfied original author's code for reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, x_train, y_train, batch_size, epochs, x_valid, y_valid, x_test, y_test):\n",
    "    \"\"\"Train model with the given training, validation, and test set, with appropriate batch size and # epochs.\"\"\"\n",
    "    epoch_data = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_valid, y_valid), verbose=0)\n",
    "    score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    acc = score[1]\n",
    "    score = score[0]\n",
    "    return score, acc, epoch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_busy_vs_relax_timeframes_br_hb(path, ident, seconds):\n",
    "    \"\"\"Returns raw data from either 'on task' or 'relax' time frames and their class (0 or 1).\"\"\"\n",
    "    \n",
    "    dataread = datareader.DataReader(path, ident)  # initialize path to data\n",
    "    data = dataread.read_grc_data()  # read from files\n",
    "    samp_rate = int(round(len(data[1]) / max(data[0])))\n",
    "    cog_res = dataread.read_cognitive_load_study(str(ident) + '-primary-extract.txt')\n",
    "\n",
    "    tasks_data = np.empty((0, seconds*samp_rate))\n",
    "    tasks_y = np.empty((0, 1))\n",
    "    breathing = np.empty((0,12))\n",
    "    heartbeat = np.empty((0,10))\n",
    "\n",
    "    busy_n = dataread.get_data_task_timestamps(return_indexes=True)\n",
    "    relax_n = dataread.get_relax_timestamps(return_indexes=True)\n",
    "\n",
    "    for i in cog_res['task_number']:\n",
    "        task_num_table = i - 225  # 0 - 17\n",
    "        tmp_tasks_data = np.empty((0, seconds*samp_rate))\n",
    "        tmp_tasks_y = np.empty((0, 1))\n",
    "        tmp_breathing = np.empty((0,12))\n",
    "        tmp_heartbeat = np.empty((0,10))\n",
    "\n",
    "        ### task versus relax (1 sample each)\n",
    "        dataextract = dataextractor.DataExtractor(data[0][busy_n[task_num_table][0]:busy_n[task_num_table][1]],\n",
    "                                                  data[1][busy_n[task_num_table][0]:busy_n[task_num_table][1]],\n",
    "                                                  samp_rate)\n",
    "\n",
    "        dataextract_relax = dataextractor.DataExtractor(data[0][relax_n[task_num_table][0]:relax_n[task_num_table][1]],\n",
    "                                                        data[1][relax_n[task_num_table][0]:relax_n[task_num_table][1]],\n",
    "                                                        samp_rate)\n",
    "\n",
    "        try:\n",
    "\n",
    "            # get extracted features for breathing\n",
    "            tmpBR_busy = dataextract.extract_from_breathing_time(dataextract.t[-samp_rate*seconds:],\n",
    "                                                                 dataextract.y[-samp_rate*seconds:])\n",
    "            tmpBR_relax = dataextract_relax.extract_from_breathing_time(dataextract_relax.t[-samp_rate*seconds:],\n",
    "                                                                 dataextract_relax.y[-samp_rate*seconds:])\n",
    "            #get extracted features for heartbeat\n",
    "            tmpHB_busy = dataextract.extract_from_heartbeat_time(dataextract.t[-samp_rate*seconds:],\n",
    "                                                                 dataextract.y[-samp_rate*seconds:])\n",
    "            tmpHB_relax = dataextract.extract_from_heartbeat_time(dataextract_relax.t[-samp_rate*seconds:],\n",
    "                                                                 dataextract_relax.y[-samp_rate*seconds:])\n",
    "\n",
    "            tmp_tasks_data = np.vstack((tmp_tasks_data, dataextract.y[-samp_rate * seconds:]))\n",
    "            tmp_tasks_y = np.vstack((tasks_y, 1))\n",
    "            tmp_tasks_data = np.vstack((tmp_tasks_data, dataextract_relax.y[-samp_rate * seconds:]))\n",
    "            tmp_tasks_y = np.vstack((tmp_tasks_y, 0))\n",
    "\n",
    "            # put busy frames then relaxed frames under the previous frames\n",
    "            tmp_breathing = np.vstack((tmp_breathing, tmpBR_busy.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "            tmp_breathing = np.vstack((tmp_breathing, tmpBR_relax.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "\n",
    "            tmp_heartbeat = np.vstack((tmp_heartbeat, tmpHB_busy.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "            tmp_heartbeat = np.vstack((tmp_heartbeat, tmpHB_relax.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "\n",
    "        except ValueError:\n",
    "#             print(ident)  # ignore short windows\n",
    "            continue\n",
    "\n",
    "        # put busy frames then relaxed frames under the previous frames\n",
    "        tasks_data = np.vstack((tasks_data, dataextract.y[-samp_rate * seconds:]))\n",
    "        tasks_y = np.vstack((tasks_y, 1))\n",
    "        tasks_data = np.vstack((tasks_data, dataextract_relax.y[-samp_rate * seconds:]))\n",
    "        tasks_y = np.vstack((tasks_y, 0))\n",
    "\n",
    "        breathing = np.vstack((breathing, tmpBR_busy.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "        breathing = np.vstack((breathing, tmpBR_relax.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "\n",
    "        heartbeat = np.vstack((heartbeat, tmpHB_busy.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "        heartbeat = np.vstack((heartbeat, tmpHB_relax.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "\n",
    "    return tasks_data, tasks_y, breathing, heartbeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_idents_br_hb(path, idents, seconds):\n",
    "    \"\"\"Go through all user data and take out windows of only <seconds> long time frames,\n",
    "    along with the given class (from 'divide_each_task' function).\n",
    "    \"\"\"\n",
    "    samp_rate = 43  # hard-coded sample rate\n",
    "    data, ys = np.empty((0, samp_rate*seconds)), np.empty((0, 1))\n",
    "    brs = np.empty((0,12))\n",
    "    hbs = np.empty((0,10))\n",
    "    combined = np.empty((0,22))\n",
    "    \n",
    "    # was gettign some weird warnings; stack overflow said to ignore them\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        for i in idents:\n",
    "            x, y, br, hb = get_busy_vs_relax_timeframes_br_hb(path, i, seconds) # either 'get_busy_vs_relax_timeframes',\n",
    "            # get_engagement_increase_vs_decrease_timeframes, get_task_complexities_timeframes or get_TLX_timeframes\n",
    "\n",
    "            data = np.vstack((data, x))\n",
    "            ys = np.vstack((ys, y))\n",
    "            brs = np.vstack((brs, br))\n",
    "            hbs = np.vstack((hbs, hb))\n",
    "        combined = np.hstack((brs,hbs))\n",
    "    \n",
    "    return data, ys, brs, hbs, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(x, standardScaler=True, minMaxScaler=True):\n",
    "    \n",
    "    if standardScaler:\n",
    "        # Scale with standard scaler\n",
    "        sscaler = StandardScaler()\n",
    "        sscaler.fit(x)\n",
    "        x = sscaler.transform(x)\n",
    "\n",
    "    if minMaxScaler:\n",
    "        # Scale with MinMax to range [0,1]\n",
    "        mmscaler = MinMaxScaler((0,1))\n",
    "        mmscaler.fit(x)\n",
    "        x = mmscaler.transform(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accs is a dictionary which holds 1d arrays of accuracies in each key\n",
    "# except the key 'test id' which holds strings of the id which yielded the coresponding accuracies\n",
    "def print_accs_stats(accs):\n",
    "    \n",
    "    printDict = {}\n",
    "    # loop over each key\n",
    "    for key in accs:\n",
    "    \n",
    "        if (key == 'test id'):\n",
    "            # skip calculating ids\n",
    "            continue\n",
    "        printDict[key] = {}\n",
    "        tmpDict = printDict[key]\n",
    "        # calculate and print some statistics\n",
    "        tmpDict['min'] = np.min(accs[key])\n",
    "        tmpDict['max'] = np.max(accs[key])\n",
    "        tmpDict['mean'] = np.mean(accs[key])\n",
    "        tmpDict['median'] = np.median(accs[key])\n",
    "    \n",
    "    print(pandas.DataFrame.from_dict(printDict).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds():\n",
    "    # clear session and set seeds again\n",
    "    # cannot clear session due to tf.compat.v1 graphs, but add tf.compat.v1.set_random_seed\n",
    "#     K.clear_session()\n",
    "    tf.compat.v1.set_random_seed(2)\n",
    "    random.seed(1)\n",
    "    np.random.seed(4)\n",
    "    tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undercomplete Autoencoder  \n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undercomplete_ae(x, encoding_dim=64, encoded_as_model=False):\n",
    "    # Simplest possible autoencoder from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_data = Input(shape=x[0].shape, name=\"input\")\n",
    "    dropout = Dropout(0.25, name=\"dropout\")(input_data)\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='relu', name=\"encoded\")(dropout)\n",
    "    \n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(x[0].shape[0], activation='sigmoid', name=\"decoded\")(encoded)\n",
    "\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "    \n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Autoencoder  \n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_ae(x, encoding_dim=64, encoded_as_model=False):\n",
    "    # Simplest possible autoencoder from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_data = Input(shape=x[0].shape, name=\"input\")\n",
    "    dropout = Dropout(0.25, name=\"dropout\") (input_data)\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    # add a sparsity constraint\n",
    "    encoded = Dense(encoding_dim, activation='relu', name=\"encoded\",\n",
    "                    activity_regularizer=regularizers.l1(10e-5))(dropout)\n",
    "    \n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(x[0].shape[0], activation='sigmoid', name=\"decoded\")(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_data, decoded, name=\"sparse_ae\")\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "    \n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Autoencoder  \n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_ae(x, enc_layers=[512,256], encoding_dim=64, dec_layers=[256,512], encoded_as_model=False):\n",
    "    # From https://www.tensorflow.org/guide/keras/functional#use_the_same_graph_of_layers_to_define_multiple_models\n",
    "    input_data = keras.Input(shape=x[0].shape, name=\"normalized_signal\")\n",
    "    model = Dropout(0.25, name=\"dropout\", autocast=False)(input_data)\n",
    "    for i in enumerate(enc_layers):\n",
    "        model = Dense(i[1], activation=\"relu\", name=\"dense_enc_\" + str(i[0]+1))(model)\n",
    "    encoded_output = Dense(encoding_dim, activation=\"relu\", name=\"encoded_signal\")(model)\n",
    "\n",
    "    encoded = encoded_output\n",
    "\n",
    "    model = layers.Dense(dec_layers[0], activation=\"sigmoid\", name=\"dense_dec_1\")(encoded_output)\n",
    "    for i in enumerate(dec_layers[1:]):\n",
    "        model = Dense(i[1], activation=\"sigmoid\", name=\"dense_dec_\" + str(i[0]+2))(model)\n",
    "    decoded_output = Dense(x[0].shape[0], activation=\"sigmoid\", name=\"reconstructed_signal\")(model)\n",
    "    \n",
    "    autoencoder = Model(input_data, decoded_output, name=\"autoencoder\")\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "\n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contractive Autoencoder\n",
    "From: https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to be able to access the autoencoder in the loss funciton\n",
    "def loss_with_params(autoencoder):\n",
    "    # loss function from https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/\n",
    "    def contractive_loss(y_pred, y_true):\n",
    "\n",
    "        lam = 1e-4\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "\n",
    "        W = K.variable(value=autoencoder.get_layer('encoded').get_weights()[0])  # N x N_hidden\n",
    "        W = K.transpose(W)  # N_hidden x N\n",
    "        h = autoencoder.get_layer('encoded').output\n",
    "        dh = h * (1 - h)  # N_batch x N_hidden\n",
    "\n",
    "        # N_batch x N_hidden * N_hidden x 1 = N_batch x 1\n",
    "        contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "        return mse + contractive\n",
    "    return contractive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractive_ae(x, encoding_dim=64, encoded_as_model=False):\n",
    "    # From https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/\n",
    "\n",
    "    input_data = Input(shape=x[0].shape, name=\"input\")\n",
    "    encoded = Dense(encoding_dim, activation='sigmoid', name='encoded')(input_data)\n",
    "    outputs = Dense(x[0].shape[0], activation='linear', name=\"output\")(encoded)\n",
    "\n",
    "    autoencoder = Model(input_data, outputs, name=\"autoencoder\")\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss=loss_with_params(autoencoder), metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "    \n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary to store accuracies for comparison\n",
    "accuracies = {}\n",
    "\n",
    "# used for reading the data into an array\n",
    "seconds = 30  # time window length\n",
    "idents = ['2gu87', 'iz2ps', '1mpau', '7dwjy', '7swyk', '94mnx', 'bd47a', 'c24ur', 'ctsax', 'dkhty', 'e4gay',\n",
    "              'ef5rq', 'f1gjp', 'hpbxa', 'pmyfl', 'r89k1', 'tn4vl', 'td5pr', 'gyqu9', 'fzchw', 'l53hg', '3n2f9',\n",
    "              '62i9y']\n",
    "path = '../../../StudyData/'\n",
    "\n",
    "# change to len(idents) at the end to use all the data\n",
    "n = 10 #len(idents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(model, params):\n",
    "    \n",
    "    model = Dropout(params['dropout'], name='dropout_cl')(model)\n",
    "    model = Dense(params['hidden_size'], activation=params['activation'], name='dense_cl1')(model)\n",
    "    model = Dense(1, activation=params['last_activation'], name='dense_cl2')(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier_base():\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dropout': 0.24,\n",
    "    'optimizer': 'Adam',\n",
    "    'hidden_size': 32,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'last_activation': 'sigmoid',\n",
    "    'activation': 'softmax',\n",
    "    'batch_size': 256,\n",
    "    'epochs': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00.007983\n",
      "WARNING:tensorflow:From D:\\Miscellanious\\Anaconda\\envs\\py37talos\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "iteration: 2 of 10 ; time elapsed: 0:01:02.815492\n",
      "iteration: 3 of 10 ; time elapsed: 0:02:13.373106\n",
      "iteration: 4 of 10 ; time elapsed: 0:03:31.528102\n",
      "iteration: 5 of 10 ; time elapsed: 0:04:58.975050\n",
      "iteration: 6 of 10 ; time elapsed: 0:06:34.209059\n",
      "iteration: 7 of 10 ; time elapsed: 0:08:18.948272\n",
      "iteration: 8 of 10 ; time elapsed: 0:10:14.032609\n",
      "iteration: 9 of 10 ; time elapsed: 0:12:20.634588\n",
      "iteration: 10 of 10 ; time elapsed: 0:14:37.126364\n",
      "Completed! Time elapsed: 0:17:11.856668\n"
     ]
    }
   ],
   "source": [
    "# set the variables in the dictionary\n",
    "accuracies['simple_dense'] = {}\n",
    "accs = accuracies['simple_dense']\n",
    "accs['phase'] = []\n",
    "accs['breathing'] = []\n",
    "accs['heartbeat'] = []\n",
    "accs['combined br hb'] = []\n",
    "accs['undercomplete'] = []\n",
    "accs['sparse'] = []\n",
    "accs['deep'] = []\n",
    "accs['contractive'] = []\n",
    "accs['test id'] = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # leave out person out validation\n",
    "    for i in range(n):\n",
    "\n",
    "        # print current iteration and time elapsed from start\n",
    "        print(\"iteration:\", i+1, \"of\", n, \"; time elapsed:\", datetime.now()-start_time)\n",
    "\n",
    "        ## ----- Data preparation:\n",
    "        validation_idents = [idents[i]]\n",
    "        test_idents = [idents[i-1]]\n",
    "\n",
    "        train_idents = []\n",
    "        for ident in idents:\n",
    "            if (ident not in test_idents) and (ident not in validation_idents):\n",
    "                train_idents.append(ident)\n",
    "        \n",
    "        # save test id to see which id yielded which accuracies\n",
    "        accs['test id'].append(test_idents[0])\n",
    "\n",
    "        # Load data (xt-raw phase data, y-class, br-breathing data, hb-heartbeat data, cmb-combined [br,hb])\n",
    "        xt_train, y_train, br_train, hb_train, cmb_train = get_data_from_idents_br_hb(path, train_idents, seconds)\n",
    "        xt_valid, y_valid, br_valid, hb_valid, cmb_valid = get_data_from_idents_br_hb(path, validation_idents, seconds)\n",
    "        xt_test, y_test, br_test, hb_test, cmb_test = get_data_from_idents_br_hb(path, test_idents, seconds)\n",
    "\n",
    "        # Scale data with standard scaler then MinMax scaler\n",
    "        # Raw Phase data:\n",
    "        xt_train = scale_data(xt_train, standardScaler=True, minMaxScaler=True)\n",
    "        xt_valid = scale_data(xt_valid, standardScaler=True, minMaxScaler=True)\n",
    "        xt_test = scale_data(xt_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted breathing data:\n",
    "        br_train = scale_data(br_train, standardScaler=True, minMaxScaler=True)\n",
    "        br_valid = scale_data(br_valid, standardScaler=True, minMaxScaler=True)\n",
    "        br_test = scale_data(br_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted Heartbeat data:\n",
    "        hb_train = scale_data(hb_train, standardScaler=True, minMaxScaler=True)\n",
    "        hb_valid = scale_data(hb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        hb_test = scale_data(hb_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Combined breathing and heartbeat data (joined together into one matrix)\n",
    "        cmb_train = scale_data(cmb_train, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_valid = scale_data(cmb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_test = scale_data(cmb_test, standardScaler=True, minMaxScaler=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## ----- Classify without autoencoders:\n",
    "        # Phase classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['phase'].append(curr_acc)\n",
    "\n",
    "        # Breathing classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, br_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               br_valid, y_valid, br_test, y_test)\n",
    "        accs['breathing'].append(curr_acc)\n",
    "\n",
    "        # Heartbeat classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, hb_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               hb_valid, y_valid, hb_test, y_test)\n",
    "        accs['heartbeat'].append(curr_acc)\n",
    "\n",
    "        # Combined classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, cmb_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               cmb_valid, y_valid, cmb_test, y_test)\n",
    "        accs['combined br hb'].append(curr_acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## ----- Classify with autoencoders:\n",
    "        # AE Training params\n",
    "        batch_size = 256\n",
    "        epochs = 100\n",
    "        encoding_dim = 64\n",
    "\n",
    "        # Undercomplete AE:\n",
    "        autoencoder, encoded = undercomplete_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['undercomplete'].append(curr_acc)\n",
    "\n",
    "        # Sparse AE:\n",
    "        autoencoder, encoded = sparse_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['sparse'].append(curr_acc)\n",
    "\n",
    "        # Deep AE:\n",
    "        autoencoder, encoded = deep_ae(xt_train, enc_layers=[512,256], encoding_dim=encoding_dim, dec_layers=[256,512])\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['deep'].append(curr_acc)\n",
    "\n",
    "        # Contractive AE:\n",
    "        autoencoder, encoded = contractive_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['contractive'].append(curr_acc)\n",
    "\n",
    "# Print total time required to run this\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Completed!\", \"Time elapsed:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>bd47a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>c24ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>ctsax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.416667   0.500000   0.583333        0.375000       0.458333  0.458333   \n",
       "1  0.794118   0.735294   0.382353        0.588235       0.764706  0.735294   \n",
       "2  0.611111   0.722222   0.416667        0.805556       0.611111  0.694444   \n",
       "3  0.558824   0.735294   0.529412        0.764706       0.558824  0.676471   \n",
       "4  0.500000   0.566667   0.566667        0.466667       0.600000  0.600000   \n",
       "5  0.593750   0.906250   0.562500        0.875000       0.687500  0.812500   \n",
       "6  0.593750   0.687500   0.625000        0.656250       0.500000  0.593750   \n",
       "7  0.533333   0.700000   0.600000        0.666667       0.666667  0.633333   \n",
       "8  0.533333   0.800000   0.700000        0.766667       0.666667  0.566667   \n",
       "9  0.600000   0.833333   0.600000        0.833333       0.600000  0.666667   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.416667     0.375000   62i9y  \n",
       "1  0.735294     0.588235   2gu87  \n",
       "2  0.611111     0.555556   iz2ps  \n",
       "3  0.529412     0.588235   1mpau  \n",
       "4  0.466667     0.700000   7dwjy  \n",
       "5  0.500000     0.687500   7swyk  \n",
       "6  0.593750     0.500000   94mnx  \n",
       "7  0.633333     0.633333   bd47a  \n",
       "8  0.600000     0.466667   c24ur  \n",
       "9  0.633333     0.600000   ctsax  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.416667   0.500000   0.382353        0.375000       0.458333  0.458333  0.416667     0.375000\n",
      "max     0.794118   0.906250   0.700000        0.875000       0.764706  0.812500  0.735294     0.700000\n",
      "mean    0.573489   0.718656   0.556593        0.679808       0.611381  0.643746  0.571957     0.569453\n",
      "median  0.576287   0.728758   0.575000        0.715686       0.605556  0.650000  0.596875     0.588235\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM-based classifier  \n",
    "based on the original author's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize hyperparameters with talos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_classifier(model, params):\n",
    "\n",
    "    model = layers.Reshape((-1, 1), input_shape=(model.shape), name='reshape_cl') (model)\n",
    "\n",
    "    model = layers.Dropout(params['dropout'], name='dropout_cl1') (model)\n",
    "    \n",
    "    model = Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides'],\n",
    "                     name='conv1d_cl1') (model)\n",
    "    \n",
    "    model = MaxPooling1D(pool_size=params['pool_size'], name='maxpool_cl1') (model)\n",
    "    \n",
    "    model = Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides'],\n",
    "                     name='conv1d_cl2') (model)\n",
    "    \n",
    "    model = MaxPooling1D(pool_size=params['pool_size'], name='maxpool_cl2') (model)\n",
    "    \n",
    "    model = layers.Dropout(params['dropout'], name='dropout_cl2') (model)\n",
    "\n",
    "    model = LSTM(params['lstm_output_size'], activation='sigmoid', name='lstm_cl') (model)\n",
    "\n",
    "    model = Dense(1, activation=params['last_activation'], name='dense_cl') (model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_classifier_base(params):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides']))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=params['pool_size']))\n",
    "    model.add(Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides']))\n",
    "    model.add(MaxPooling1D(pool_size=params['pool_size']))\n",
    "\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(LSTM(params['lstm_output_size']))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(params['last_activation']))\n",
    "\n",
    "    model.compile(loss=params['loss'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_phase = {\n",
    "    'kernel_size': 32,\n",
    "    'strides': 4,\n",
    "    'pool_size': 2,\n",
    "    'filters': 8,\n",
    "    'lstm_output_size': 236,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'dropout': 0.09,\n",
    "    'activation': 'relu',\n",
    "    'optimizer': 'Nadam',\n",
    "    'last_activation': 'sigmoid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_br_hb = {\n",
    "    'kernel_size': 2,\n",
    "    'strides': 1,\n",
    "    'pool_size': 1,\n",
    "    'filters': 2,\n",
    "    'lstm_output_size': 4,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'dropout': 0.09,\n",
    "    'activation': 'relu',\n",
    "    'optimizer': 'Nadam',\n",
    "    'last_activation': 'sigmoid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel_size': 4,\n",
    "    'filters': 2,\n",
    "    'strides': 2,\n",
    "    'pool_size': 2,\n",
    "    'dropout': 0.09,\n",
    "    'optimizer': 'Nadam',\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'activation': 'relu',\n",
    "    'last_activation': 'sigmoid',\n",
    "    'lstm_output_size': 32,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00.007980\n",
      "iteration: 2 of 10 ; time elapsed: 0:07:32.942588\n",
      "iteration: 3 of 10 ; time elapsed: 0:16:17.983277\n",
      "iteration: 4 of 10 ; time elapsed: 0:26:27.489231\n",
      "iteration: 5 of 10 ; time elapsed: 0:38:16.004422\n",
      "Completed! Time elapsed: 0:52:39.377632\n"
     ]
    }
   ],
   "source": [
    "# set the variables in the dictionary\n",
    "accuracies['LSTM'] = {}\n",
    "accs = accuracies['LSTM']\n",
    "accs['phase'] = []\n",
    "accs['breathing'] = []\n",
    "accs['heartbeat'] = []\n",
    "accs['combined br hb'] = []\n",
    "accs['undercomplete'] = []\n",
    "accs['sparse'] = []\n",
    "accs['deep'] = []\n",
    "accs['contractive'] = []\n",
    "accs['test id'] = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # leave out person out validation\n",
    "    for i in range(5): ##### <--------------------------------- TODO: change to range(n)\n",
    "\n",
    "        # print current iteration and time elapsed from start\n",
    "        print(\"iteration:\", i+1, \"of\", n, \"; time elapsed:\", datetime.now()-start_time)\n",
    "\n",
    "        ## ----- Data preparation:\n",
    "        validation_idents = [idents[i]]\n",
    "        test_idents = [idents[i-1]]\n",
    "\n",
    "        train_idents = []\n",
    "        for ident in idents:\n",
    "            if (ident not in test_idents) and (ident not in validation_idents):\n",
    "                train_idents.append(ident)\n",
    "\n",
    "        # save test id to see which id yielded which accuracies\n",
    "        accs['test id'].append(test_idents[0])\n",
    "        \n",
    "        # Load data (xt-raw phase data, y-class, br-breathing data, hb-heartbeat data, cmb-combined [br,hb])\n",
    "        xt_train, y_train, br_train, hb_train, cmb_train = get_data_from_idents_br_hb(path, train_idents, seconds)\n",
    "        xt_valid, y_valid, br_valid, hb_valid, cmb_valid = get_data_from_idents_br_hb(path, validation_idents, seconds)\n",
    "        xt_test, y_test, br_test, hb_test, cmb_test = get_data_from_idents_br_hb(path, test_idents, seconds)\n",
    "\n",
    "        # Scale data with standard scaler then MinMax scaler\n",
    "        # Raw Phase data:\n",
    "        xt_train = scale_data(xt_train, standardScaler=True, minMaxScaler=True)\n",
    "        xt_valid = scale_data(xt_valid, standardScaler=True, minMaxScaler=True)\n",
    "        xt_test = scale_data(xt_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted breathing data:\n",
    "        br_train = scale_data(br_train, standardScaler=True, minMaxScaler=True)\n",
    "        br_valid = scale_data(br_valid, standardScaler=True, minMaxScaler=True)\n",
    "        br_test = scale_data(br_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted Heartbeat data:\n",
    "        hb_train = scale_data(hb_train, standardScaler=True, minMaxScaler=True)\n",
    "        hb_valid = scale_data(hb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        hb_test = scale_data(hb_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Combined breathing and heartbeat data (joined together into one matrix)\n",
    "        cmb_train = scale_data(cmb_train, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_valid = scale_data(cmb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_test = scale_data(cmb_test, standardScaler=True, minMaxScaler=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## ----- Classify without autoencoders:\n",
    "        # Phase classifier:\n",
    "        model = LSTM_classifier_base(params_phase)\n",
    "        # reshape data for the classifier\n",
    "        xtt_train = xt_train.reshape(-1, xt_train[0].shape[0], 1)\n",
    "        xtt_valid = xt_valid.reshape(-1, xt_valid[0].shape[0], 1)\n",
    "        xtt_test = xt_test.reshape(-1, xt_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, xtt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xtt_valid, y_valid, xtt_test, y_test)\n",
    "        accs['phase'].append(curr_acc)\n",
    "\n",
    "        # Breathing classifier:\n",
    "        model = LSTM_classifier_base(params_br_hb)\n",
    "        # reshape data for the classifier\n",
    "        brt_train = br_train.reshape(-1, br_train[0].shape[0], 1)\n",
    "        brt_valid = br_valid.reshape(-1, br_valid[0].shape[0], 1)\n",
    "        brt_test = br_test.reshape(-1, br_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, brt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               brt_valid, y_valid, brt_test, y_test)\n",
    "        accs['breathing'].append(curr_acc)\n",
    "\n",
    "        # Heartbeat classifier:\n",
    "        model = LSTM_classifier_base(params_br_hb)\n",
    "        # reshape data for the classifier\n",
    "        hbt_train = hb_train.reshape(-1, hb_train[0].shape[0], 1)\n",
    "        hbt_valid = hb_valid.reshape(-1, hb_valid[0].shape[0], 1)\n",
    "        hbt_test = hb_test.reshape(-1, hb_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, hbt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               hbt_valid, y_valid, hbt_test, y_test)\n",
    "        accs['heartbeat'].append(curr_acc)\n",
    "\n",
    "        # Combined classifier:\n",
    "        model = LSTM_classifier_base(params_br_hb)\n",
    "        # reshape data for the classifier\n",
    "        cmbt_train = cmb_train.reshape(-1, cmb_train[0].shape[0], 1)\n",
    "        cmbt_valid = cmb_valid.reshape(-1, cmb_valid[0].shape[0], 1)\n",
    "        cmbt_test = cmb_test.reshape(-1, cmb_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, cmbt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               cmbt_valid, y_valid, cmbt_test, y_test)\n",
    "        accs['combined br hb'].append(curr_acc)\n",
    "\n",
    "        \n",
    "        \n",
    "        ## ----- Classify with autoencoders:\n",
    "        # AE Training params\n",
    "        batch_size = 256\n",
    "        epochs = 100\n",
    "        encoding_dim = 64\n",
    "\n",
    "        # undercomplete AE\n",
    "        autoencoder, encoded = undercomplete_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['undercomplete'].append(curr_acc)\n",
    "\n",
    "        # sparse AE\n",
    "        autoencoder, encoded = sparse_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['sparse'].append(curr_acc)\n",
    "\n",
    "        # deep AE\n",
    "        autoencoder, encoded = deep_ae(xt_train, enc_layers=[512,256], encoding_dim=encoding_dim, dec_layers=[256,512])\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['deep'].append(curr_acc)\n",
    "\n",
    "        # contractive AE\n",
    "        autoencoder, encoded = contractive_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['contractive'].append(curr_acc)\n",
    "\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Completed!\", \"Time elapsed:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.541667   0.541667   0.500000        0.333333       0.416667  0.416667   \n",
       "1  0.735294   0.294118   0.294118        0.470588       0.794118  0.735294   \n",
       "2  0.833333   0.666667   0.333333        0.388889       0.638889  0.722222   \n",
       "3  0.588235   0.705882   0.500000        0.705882       0.558824  0.705882   \n",
       "4  0.766667   0.600000   0.333333        0.700000       0.633333  0.500000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.666667     0.416667   62i9y  \n",
       "1  0.529412     0.852941   2gu87  \n",
       "2  0.750000     0.583333   iz2ps  \n",
       "3  0.529412     0.676471   1mpau  \n",
       "4  0.600000     0.566667   7dwjy  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.541667   0.294118   0.294118        0.333333       0.416667  0.416667  0.529412     0.416667\n",
      "max     0.833333   0.705882   0.500000        0.705882       0.794118  0.735294  0.750000     0.852941\n",
      "mean    0.693039   0.561667   0.392157        0.519739       0.608366  0.616013  0.615098     0.619216\n",
      "median  0.735294   0.600000   0.333333        0.470588       0.633333  0.705882  0.600000     0.583333\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper loop function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper loop funciton for the sklearn and XGBoost classifiers\n",
    "def helper_loop(classifier_function, idents, n=5):\n",
    "    #returns a dictionary with accuracies\n",
    "\n",
    "    # set the variables in the dictionary\n",
    "    accs = {}\n",
    "    accs['phase'] = []\n",
    "    accs['breathing'] = []\n",
    "    accs['heartbeat'] = []\n",
    "    accs['combined br hb'] = []\n",
    "    accs['undercomplete'] = []\n",
    "    accs['sparse'] = []\n",
    "    accs['deep'] = []\n",
    "    accs['contractive'] = []\n",
    "    accs['test id'] = []\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    with tf.compat.v1.Session(config=config) as sess:\n",
    "        # leave out person out validation\n",
    "        for i in range(n):\n",
    "\n",
    "            # print current iteration and time elapsed from start\n",
    "            print(\"iteration:\", i+1, \"of\", n, \"; time elapsed:\", datetime.now()-start_time)\n",
    "\n",
    "            ## ----- Data preparation:\n",
    "            validation_idents = [idents[i]]\n",
    "            test_idents = [idents[i-1]]\n",
    "\n",
    "            train_idents = []\n",
    "            for ident in idents:\n",
    "                if (ident not in test_idents) and (ident not in validation_idents):\n",
    "                    train_idents.append(ident)\n",
    "\n",
    "            # save test id to see which id yielded which accuracies\n",
    "            accs['test id'].append(test_idents[0])\n",
    "\n",
    "            # Load data (xt-raw phase data, y-class, br-breathing data, hb-heartbeat data, cmb-combined [br,hb])\n",
    "            xt_train, y_train, br_train, hb_train, cmb_train = get_data_from_idents_br_hb(path, train_idents, seconds)\n",
    "            xt_valid, y_valid, br_valid, hb_valid, cmb_valid = get_data_from_idents_br_hb(path, validation_idents, seconds)\n",
    "            xt_test, y_test, br_test, hb_test, cmb_test = get_data_from_idents_br_hb(path, test_idents, seconds)\n",
    "\n",
    "            # change the y arrays to flat 1d arrays\n",
    "            y_train = y_train.ravel()\n",
    "            y_valid = y_valid.ravel()\n",
    "            y_test = y_test.ravel()\n",
    "            \n",
    "            # Scale data with standard scaler then MinMax scaler\n",
    "            # Raw Phase data:\n",
    "            xt_train = scale_data(xt_train, standardScaler=True, minMaxScaler=True)\n",
    "            xt_valid = scale_data(xt_valid, standardScaler=True, minMaxScaler=True)\n",
    "            xt_test = scale_data(xt_test, standardScaler=True, minMaxScaler=True)\n",
    "            # Hand extracted breathing data:\n",
    "            br_train = scale_data(br_train, standardScaler=True, minMaxScaler=True)\n",
    "            br_valid = scale_data(br_valid, standardScaler=True, minMaxScaler=True)\n",
    "            br_test = scale_data(br_test, standardScaler=True, minMaxScaler=True)\n",
    "            # Hand extracted Heartbeat data:\n",
    "            hb_train = scale_data(hb_train, standardScaler=True, minMaxScaler=True)\n",
    "            hb_valid = scale_data(hb_valid, standardScaler=True, minMaxScaler=True)\n",
    "            hb_test = scale_data(hb_test, standardScaler=True, minMaxScaler=True)\n",
    "            # Combined breathing and heartbeat data (joined together into one matrix)\n",
    "            cmb_train = scale_data(cmb_train, standardScaler=True, minMaxScaler=True)\n",
    "            cmb_valid = scale_data(cmb_valid, standardScaler=True, minMaxScaler=True)\n",
    "            cmb_test = scale_data(cmb_test, standardScaler=True, minMaxScaler=True)\n",
    "\n",
    "            \n",
    "\n",
    "            ## ----- Classify without autoencoders:\n",
    "            # Phase classifier:\n",
    "            set_random_seeds()\n",
    "            model = classifier_function()\n",
    "            model.fit(xt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xt_test) == y_test) / len(y_test)\n",
    "            accs['phase'].append(curr_acc)\n",
    "            \n",
    "            # Breathing classifier:\n",
    "            set_random_seeds()\n",
    "            base_model = classifier_function()\n",
    "            base_model.fit(br_train, y_train)\n",
    "            curr_acc = np.sum(base_model.predict(br_test) == y_test) / len(y_test)\n",
    "            accs['breathing'].append(curr_acc)\n",
    "\n",
    "            # Heartbeat classifier:\n",
    "            set_random_seeds()\n",
    "            base_model = classifier_function()\n",
    "            base_model.fit(hb_train, y_train)\n",
    "            curr_acc = np.sum(base_model.predict(hb_test) == y_test) / len(y_test)\n",
    "            accs['heartbeat'].append(curr_acc)\n",
    "\n",
    "            # Combined classifier:\n",
    "            set_random_seeds()\n",
    "            base_model = classifier_function()\n",
    "            base_model.fit(cmb_train, y_train)\n",
    "            curr_acc = np.sum(base_model.predict(cmb_test) == y_test) / len(y_test)\n",
    "            accs['combined br hb'].append(curr_acc)\n",
    "\n",
    "\n",
    "\n",
    "            ## ----- Classify with autoencoders:\n",
    "            # AE Training params\n",
    "            batch_size = 256\n",
    "            epochs = 100\n",
    "            encoding_dim = 64\n",
    "\n",
    "            # undercomplete AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = undercomplete_ae(xt_train, encoding_dim, encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['undercomplete'].append(curr_acc)\n",
    "\n",
    "            # sparse AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = sparse_ae(xt_train, encoding_dim, encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['sparse'].append(curr_acc)\n",
    "\n",
    "            # deep AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = deep_ae(xt_train, enc_layers=[512,256], encoding_dim=encoding_dim, dec_layers=[256,512], encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['deep'].append(curr_acc)\n",
    "\n",
    "            # contractive AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = contractive_ae(xt_train, encoding_dim, encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['contractive'].append(curr_acc)\n",
    "\n",
    "    # Print total time required to run this\n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Completed!\", \"Time elapsed:\", elapsed_time)\n",
    "    \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def KNN_classifier():\n",
    "    model = KNeighborsClassifier(p=3, n_neighbors=7, metric='cosine')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00.006868\n",
      "iteration: 2 of 10 ; time elapsed: 0:03:34.286554\n",
      "iteration: 3 of 10 ; time elapsed: 0:07:26.667358\n",
      "iteration: 4 of 10 ; time elapsed: 0:11:41.780649\n",
      "iteration: 5 of 10 ; time elapsed: 0:16:14.355082\n",
      "iteration: 6 of 10 ; time elapsed: 0:21:11.670588\n",
      "iteration: 7 of 10 ; time elapsed: 0:26:25.721028\n",
      "iteration: 8 of 10 ; time elapsed: 0:31:45.418098\n",
      "iteration: 9 of 10 ; time elapsed: 0:37:04.764994\n",
      "iteration: 10 of 10 ; time elapsed: 0:42:40.801805\n",
      "Completed! Time elapsed: 0:49:50.872476\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(KNN_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['kNN'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>bd47a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>c24ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>ctsax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.500000   0.458333   0.333333        0.416667       0.500000  0.500000   \n",
       "1  0.588235   0.647059   0.352941        0.676471       0.823529  0.558824   \n",
       "2  0.638889   0.638889   0.472222        0.750000       0.611111  0.638889   \n",
       "3  0.676471   0.676471   0.441176        0.617647       0.588235  0.647059   \n",
       "4  0.700000   0.600000   0.400000        0.600000       0.533333  0.600000   \n",
       "5  0.812500   0.812500   0.437500        0.781250       0.593750  0.625000   \n",
       "6  0.687500   0.531250   0.562500        0.531250       0.656250  0.500000   \n",
       "7  0.600000   0.633333   0.600000        0.700000       0.700000  0.633333   \n",
       "8  0.700000   0.700000   0.533333        0.700000       0.600000  0.500000   \n",
       "9  0.666667   0.833333   0.466667        0.733333       0.700000  0.800000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.416667     0.625000   62i9y  \n",
       "1  0.647059     0.617647   2gu87  \n",
       "2  0.611111     0.611111   iz2ps  \n",
       "3  0.588235     0.441176   1mpau  \n",
       "4  0.666667     0.633333   7dwjy  \n",
       "5  0.531250     0.562500   7swyk  \n",
       "6  0.562500     0.593750   94mnx  \n",
       "7  0.600000     0.500000   bd47a  \n",
       "8  0.600000     0.600000   c24ur  \n",
       "9  0.500000     0.666667   ctsax  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete   sparse      deep  contractive\n",
      "min     0.500000   0.458333   0.333333        0.416667       0.500000  0.50000  0.416667     0.441176\n",
      "max     0.812500   0.833333   0.600000        0.781250       0.823529  0.80000  0.666667     0.666667\n",
      "mean    0.657026   0.653117   0.459967        0.650662       0.630621  0.60031  0.572349     0.585118\n",
      "median  0.671569   0.642974   0.453922        0.688235       0.605556  0.61250  0.594118     0.605556\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def SVC_classifier():\n",
    "    model = SVC(kernel='rbf', C=1.5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00\n",
      "iteration: 2 of 10 ; time elapsed: 0:03:49.998369\n",
      "iteration: 3 of 10 ; time elapsed: 0:08:00.404254\n",
      "iteration: 4 of 10 ; time elapsed: 0:12:37.615514\n",
      "iteration: 5 of 10 ; time elapsed: 0:17:43.294081\n",
      "iteration: 6 of 10 ; time elapsed: 0:23:23.011519\n",
      "iteration: 7 of 10 ; time elapsed: 0:29:06.546522\n",
      "iteration: 8 of 10 ; time elapsed: 0:35:25.707640\n",
      "iteration: 9 of 10 ; time elapsed: 0:42:20.816218\n",
      "iteration: 10 of 10 ; time elapsed: 0:49:47.072801\n",
      "Completed! Time elapsed: 0:58:52.162650\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(SVC_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['SVC'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>bd47a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>c24ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>ctsax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.416667   0.500000   0.500000        0.500000       0.333333  0.500000   \n",
       "1  0.676471   0.705882   0.352941        0.735294       0.588235  0.705882   \n",
       "2  0.777778   0.666667   0.333333        0.750000       0.527778  0.694444   \n",
       "3  0.529412   0.764706   0.588235        0.764706       0.441176  0.500000   \n",
       "4  0.666667   0.533333   0.466667        0.566667       0.600000  0.566667   \n",
       "5  0.468750   0.656250   0.656250        0.781250       0.468750  0.593750   \n",
       "6  0.656250   0.625000   0.656250        0.625000       0.593750  0.468750   \n",
       "7  0.633333   0.633333   0.633333        0.566667       0.566667  0.566667   \n",
       "8  0.733333   0.733333   0.566667        0.766667       0.566667  0.633333   \n",
       "9  0.633333   0.866667   0.566667        0.700000       0.500000  0.600000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.458333     0.416667   62i9y  \n",
       "1  0.588235     0.735294   2gu87  \n",
       "2  0.555556     0.638889   iz2ps  \n",
       "3  0.441176     0.529412   1mpau  \n",
       "4  0.633333     0.566667   7dwjy  \n",
       "5  0.625000     0.468750   7swyk  \n",
       "6  0.687500     0.625000   94mnx  \n",
       "7  0.500000     0.600000   bd47a  \n",
       "8  0.533333     0.600000   c24ur  \n",
       "9  0.566667     0.533333   ctsax  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.416667   0.500000   0.333333        0.500000       0.333333  0.468750  0.441176     0.416667\n",
      "max     0.777778   0.866667   0.656250        0.781250       0.600000  0.705882  0.687500     0.735294\n",
      "mean    0.619199   0.668517   0.532034        0.675625       0.518636  0.582949  0.558913     0.571401\n",
      "median  0.644792   0.661458   0.566667        0.717647       0.547222  0.580208  0.561111     0.583333\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def random_forest_classifier():\n",
    "    model = RandomForestClassifier(n_estimators = 250,\n",
    "                                     min_samples_split = 10,\n",
    "                                     min_samples_leaf = 4,\n",
    "                                     max_features = 'auto',\n",
    "                                     max_depth = 90,\n",
    "                                     bootstrap = True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00\n",
      "iteration: 2 of 10 ; time elapsed: 0:04:48.687027\n",
      "iteration: 3 of 10 ; time elapsed: 0:10:06.150430\n",
      "iteration: 4 of 10 ; time elapsed: 0:16:05.568345\n",
      "iteration: 5 of 10 ; time elapsed: 0:22:59.438858\n",
      "iteration: 6 of 10 ; time elapsed: 0:30:21.932782\n",
      "iteration: 7 of 10 ; time elapsed: 0:38:20.992617\n",
      "iteration: 8 of 10 ; time elapsed: 0:46:57.970766\n",
      "iteration: 9 of 10 ; time elapsed: 0:56:04.322792\n",
      "iteration: 10 of 10 ; time elapsed: 1:05:36.305051\n",
      "Completed! Time elapsed: 1:17:44.588450\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(random_forest_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['random_forest'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>bd47a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>c24ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>ctsax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.458333   0.458333   0.541667        0.500000       0.458333  0.458333   \n",
       "1  0.617647   0.647059   0.264706        0.647059       0.676471  0.764706   \n",
       "2  0.638889   0.777778   0.444444        0.722222       0.750000  0.694444   \n",
       "3  0.558824   0.764706   0.529412        0.647059       0.500000  0.529412   \n",
       "4  0.500000   0.566667   0.433333        0.533333       0.566667  0.533333   \n",
       "5  0.562500   0.718750   0.562500        0.718750       0.593750  0.625000   \n",
       "6  0.593750   0.656250   0.750000        0.593750       0.593750  0.437500   \n",
       "7  0.533333   0.633333   0.533333        0.633333       0.566667  0.733333   \n",
       "8  0.533333   0.666667   0.633333        0.633333       0.433333  0.433333   \n",
       "9  0.733333   0.733333   0.566667        0.733333       0.666667  0.700000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.375000     0.458333   62i9y  \n",
       "1  0.647059     0.705882   2gu87  \n",
       "2  0.583333     0.888889   iz2ps  \n",
       "3  0.617647     0.588235   1mpau  \n",
       "4  0.566667     0.533333   7dwjy  \n",
       "5  0.562500     0.500000   7swyk  \n",
       "6  0.625000     0.562500   94mnx  \n",
       "7  0.533333     0.500000   bd47a  \n",
       "8  0.500000     0.500000   c24ur  \n",
       "9  0.700000     0.666667   ctsax  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.458333   0.458333   0.264706        0.500000       0.433333  0.433333  0.375000     0.458333\n",
      "max     0.733333   0.777778   0.750000        0.733333       0.750000  0.764706  0.700000     0.888889\n",
      "mean    0.572994   0.662288   0.525940        0.636217       0.580564  0.590940  0.571054     0.590384\n",
      "median  0.560662   0.661458   0.537500        0.640196       0.580208  0.579167  0.575000     0.547917\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "def naive_bayesian_classifier():\n",
    "    model = ComplementNB()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00.046641\n",
      "iteration: 2 of 10 ; time elapsed: 0:05:12.614349\n",
      "iteration: 3 of 10 ; time elapsed: 0:11:35.920935\n",
      "iteration: 4 of 10 ; time elapsed: 0:19:42.404757\n",
      "iteration: 5 of 10 ; time elapsed: 0:29:02.720470\n",
      "iteration: 6 of 10 ; time elapsed: 0:40:30.272203\n",
      "iteration: 7 of 10 ; time elapsed: 0:54:05.043907\n",
      "iteration: 8 of 10 ; time elapsed: 1:07:20.009039\n",
      "iteration: 9 of 10 ; time elapsed: 1:21:26.170789\n",
      "iteration: 10 of 10 ; time elapsed: 1:35:48.511020\n",
      "Completed! Time elapsed: 1:54:42.948537\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(naive_bayesian_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['naive_bayesian'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>bd47a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>c24ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>ctsax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.625000   0.458333   0.375000        0.458333       0.750000  0.833333   \n",
       "1  0.382353   0.676471   0.294118        0.705882       0.500000  0.529412   \n",
       "2  0.305556   0.750000   0.388889        0.750000       0.500000  0.472222   \n",
       "3  0.500000   0.823529   0.441176        0.823529       0.441176  0.500000   \n",
       "4  0.433333   0.466667   0.466667        0.466667       0.533333  0.533333   \n",
       "5  0.687500   0.875000   0.406250        0.875000       0.718750  0.843750   \n",
       "6  0.500000   0.687500   0.531250        0.687500       0.531250  0.562500   \n",
       "7  0.400000   0.666667   0.466667        0.700000       0.533333  0.533333   \n",
       "8  0.466667   0.800000   0.666667        0.866667       0.433333  0.433333   \n",
       "9  0.666667   0.933333   0.566667        0.933333       0.566667  0.566667   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.625000     0.625000   62i9y  \n",
       "1  0.470588     0.500000   2gu87  \n",
       "2  0.444444     0.472222   iz2ps  \n",
       "3  0.500000     0.470588   1mpau  \n",
       "4  0.500000     0.466667   7dwjy  \n",
       "5  0.687500     0.656250   7swyk  \n",
       "6  0.500000     0.531250   94mnx  \n",
       "7  0.600000     0.566667   bd47a  \n",
       "8  0.633333     0.433333   c24ur  \n",
       "9  0.666667     0.533333   ctsax  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.305556   0.458333   0.294118        0.458333       0.433333  0.433333  0.444444     0.433333\n",
      "max     0.687500   0.933333   0.666667        0.933333       0.750000  0.843750  0.687500     0.656250\n",
      "mean    0.496708   0.713750   0.460335        0.726691       0.550784  0.580788  0.562753     0.525531\n",
      "median  0.483333   0.718750   0.453922        0.727941       0.532292  0.533333  0.550000     0.515625\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def XGBoost_classifier():\n",
    "    model = XGBClassifier(n_estimators = 83)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 10 ; time elapsed: 0:00:00.042596\n",
      "iteration: 2 of 10 ; time elapsed: 0:06:48.364817\n",
      "iteration: 3 of 10 ; time elapsed: 0:13:59.915302\n",
      "iteration: 4 of 10 ; time elapsed: 0:22:30.225411\n",
      "iteration: 5 of 10 ; time elapsed: 0:32:56.642506\n",
      "iteration: 6 of 10 ; time elapsed: 0:45:21.155916\n",
      "iteration: 7 of 10 ; time elapsed: 1:00:02.503103\n",
      "iteration: 8 of 10 ; time elapsed: 1:16:48.544250\n",
      "iteration: 9 of 10 ; time elapsed: 1:32:40.011866\n",
      "iteration: 10 of 10 ; time elapsed: 1:50:52.378628\n",
      "Completed! Time elapsed: 2:10:52.144726\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(XGBoost_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['XGBoost'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>bd47a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>c24ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>ctsax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.375000   0.541667   0.500000        0.500000       0.458333  0.458333   \n",
       "1  0.705882   0.676471   0.441176        0.617647       0.764706  0.588235   \n",
       "2  0.583333   0.722222   0.416667        0.666667       0.694444  0.722222   \n",
       "3  0.588235   0.705882   0.647059        0.705882       0.529412  0.647059   \n",
       "4  0.566667   0.600000   0.500000        0.533333       0.600000  0.466667   \n",
       "5  0.687500   0.843750   0.406250        0.562500       0.593750  0.687500   \n",
       "6  0.593750   0.687500   0.593750        0.593750       0.500000  0.593750   \n",
       "7  0.633333   0.666667   0.566667        0.700000       0.600000  0.666667   \n",
       "8  0.633333   0.800000   0.633333        0.733333       0.533333  0.533333   \n",
       "9  0.633333   0.666667   0.466667        0.666667       0.566667  0.500000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.458333     0.416667   62i9y  \n",
       "1  0.617647     0.558824   2gu87  \n",
       "2  0.555556     0.694444   iz2ps  \n",
       "3  0.647059     0.529412   1mpau  \n",
       "4  0.600000     0.600000   7dwjy  \n",
       "5  0.562500     0.593750   7swyk  \n",
       "6  0.562500     0.531250   94mnx  \n",
       "7  0.566667     0.600000   bd47a  \n",
       "8  0.566667     0.633333   c24ur  \n",
       "9  0.600000     0.600000   ctsax  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.375000   0.541667   0.406250        0.500000       0.458333  0.458333  0.458333     0.416667\n",
      "max     0.705882   0.843750   0.647059        0.733333       0.764706  0.722222  0.647059     0.694444\n",
      "mean    0.600037   0.691083   0.517157        0.627978       0.584065  0.586377  0.573693     0.575768\n",
      "median  0.613542   0.681985   0.500000        0.642157       0.580208  0.590993  0.566667     0.596875\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compare Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print min, max, mean, median for each clasifier/autoencoder combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- simple_dense: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.416667   0.500000   0.382353        0.375000       0.458333  0.458333  0.416667     0.375000\n",
      "max     0.794118   0.906250   0.700000        0.875000       0.764706  0.812500  0.735294     0.700000\n",
      "mean    0.573489   0.718656   0.556593        0.679808       0.611381  0.643746  0.571957     0.569453\n",
      "median  0.576287   0.728758   0.575000        0.715686       0.605556  0.650000  0.596875     0.588235\n",
      "\n",
      "\n",
      "----------- LSTM: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.541667   0.294118   0.294118        0.333333       0.416667  0.416667  0.529412     0.416667\n",
      "max     0.833333   0.705882   0.500000        0.705882       0.794118  0.735294  0.750000     0.852941\n",
      "mean    0.693039   0.561667   0.392157        0.519739       0.608366  0.616013  0.615098     0.619216\n",
      "median  0.735294   0.600000   0.333333        0.470588       0.633333  0.705882  0.600000     0.583333\n",
      "\n",
      "\n",
      "----------- kNN: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete   sparse      deep  contractive\n",
      "min     0.500000   0.458333   0.333333        0.416667       0.500000  0.50000  0.416667     0.441176\n",
      "max     0.812500   0.833333   0.600000        0.781250       0.823529  0.80000  0.666667     0.666667\n",
      "mean    0.657026   0.653117   0.459967        0.650662       0.630621  0.60031  0.572349     0.585118\n",
      "median  0.671569   0.642974   0.453922        0.688235       0.605556  0.61250  0.594118     0.605556\n",
      "\n",
      "\n",
      "----------- SVC: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.416667   0.500000   0.333333        0.500000       0.333333  0.468750  0.441176     0.416667\n",
      "max     0.777778   0.866667   0.656250        0.781250       0.600000  0.705882  0.687500     0.735294\n",
      "mean    0.619199   0.668517   0.532034        0.675625       0.518636  0.582949  0.558913     0.571401\n",
      "median  0.644792   0.661458   0.566667        0.717647       0.547222  0.580208  0.561111     0.583333\n",
      "\n",
      "\n",
      "----------- random_forest: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.458333   0.458333   0.264706        0.500000       0.433333  0.433333  0.375000     0.458333\n",
      "max     0.733333   0.777778   0.750000        0.733333       0.750000  0.764706  0.700000     0.888889\n",
      "mean    0.572994   0.662288   0.525940        0.636217       0.580564  0.590940  0.571054     0.590384\n",
      "median  0.560662   0.661458   0.537500        0.640196       0.580208  0.579167  0.575000     0.547917\n",
      "\n",
      "\n",
      "----------- naive_bayesian: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.305556   0.458333   0.294118        0.458333       0.433333  0.433333  0.444444     0.433333\n",
      "max     0.687500   0.933333   0.666667        0.933333       0.750000  0.843750  0.687500     0.656250\n",
      "mean    0.496708   0.713750   0.460335        0.726691       0.550784  0.580788  0.562753     0.525531\n",
      "median  0.483333   0.718750   0.453922        0.727941       0.532292  0.533333  0.550000     0.515625\n",
      "\n",
      "\n",
      "----------- XGBoost: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.375000   0.541667   0.406250        0.500000       0.458333  0.458333  0.458333     0.416667\n",
      "max     0.705882   0.843750   0.647059        0.733333       0.764706  0.722222  0.647059     0.694444\n",
      "mean    0.600037   0.691083   0.517157        0.627978       0.584065  0.586377  0.573693     0.575768\n",
      "median  0.613542   0.681985   0.500000        0.642157       0.580208  0.590993  0.566667     0.596875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(\"-----------\", classifier + \":\", \"-----------\")\n",
    "    accs = accuracies[classifier]\n",
    "    print_accs_stats(accs)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all accuracies in table form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_dense:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.416667   0.500000   0.583333        0.375000       0.458333  0.458333  0.416667     0.375000   62i9y\n",
      "1  0.794118   0.735294   0.382353        0.588235       0.764706  0.735294  0.735294     0.588235   2gu87\n",
      "2  0.611111   0.722222   0.416667        0.805556       0.611111  0.694444  0.611111     0.555556   iz2ps\n",
      "3  0.558824   0.735294   0.529412        0.764706       0.558824  0.676471  0.529412     0.588235   1mpau\n",
      "4  0.500000   0.566667   0.566667        0.466667       0.600000  0.600000  0.466667     0.700000   7dwjy\n",
      "5  0.593750   0.906250   0.562500        0.875000       0.687500  0.812500  0.500000     0.687500   7swyk\n",
      "6  0.593750   0.687500   0.625000        0.656250       0.500000  0.593750  0.593750     0.500000   94mnx\n",
      "7  0.533333   0.700000   0.600000        0.666667       0.666667  0.633333  0.633333     0.633333   bd47a\n",
      "8  0.533333   0.800000   0.700000        0.766667       0.666667  0.566667  0.600000     0.466667   c24ur\n",
      "9  0.600000   0.833333   0.600000        0.833333       0.600000  0.666667  0.633333     0.600000   ctsax\n",
      "\n",
      "\n",
      "LSTM:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.541667   0.541667   0.500000        0.333333       0.416667  0.416667  0.666667     0.416667   62i9y\n",
      "1  0.735294   0.294118   0.294118        0.470588       0.794118  0.735294  0.529412     0.852941   2gu87\n",
      "2  0.833333   0.666667   0.333333        0.388889       0.638889  0.722222  0.750000     0.583333   iz2ps\n",
      "3  0.588235   0.705882   0.500000        0.705882       0.558824  0.705882  0.529412     0.676471   1mpau\n",
      "4  0.766667   0.600000   0.333333        0.700000       0.633333  0.500000  0.600000     0.566667   7dwjy\n",
      "\n",
      "\n",
      "kNN:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.500000   0.458333   0.333333        0.416667       0.500000  0.500000  0.416667     0.625000   62i9y\n",
      "1  0.588235   0.647059   0.352941        0.676471       0.823529  0.558824  0.647059     0.617647   2gu87\n",
      "2  0.638889   0.638889   0.472222        0.750000       0.611111  0.638889  0.611111     0.611111   iz2ps\n",
      "3  0.676471   0.676471   0.441176        0.617647       0.588235  0.647059  0.588235     0.441176   1mpau\n",
      "4  0.700000   0.600000   0.400000        0.600000       0.533333  0.600000  0.666667     0.633333   7dwjy\n",
      "5  0.812500   0.812500   0.437500        0.781250       0.593750  0.625000  0.531250     0.562500   7swyk\n",
      "6  0.687500   0.531250   0.562500        0.531250       0.656250  0.500000  0.562500     0.593750   94mnx\n",
      "7  0.600000   0.633333   0.600000        0.700000       0.700000  0.633333  0.600000     0.500000   bd47a\n",
      "8  0.700000   0.700000   0.533333        0.700000       0.600000  0.500000  0.600000     0.600000   c24ur\n",
      "9  0.666667   0.833333   0.466667        0.733333       0.700000  0.800000  0.500000     0.666667   ctsax\n",
      "\n",
      "\n",
      "SVC:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.416667   0.500000   0.500000        0.500000       0.333333  0.500000  0.458333     0.416667   62i9y\n",
      "1  0.676471   0.705882   0.352941        0.735294       0.588235  0.705882  0.588235     0.735294   2gu87\n",
      "2  0.777778   0.666667   0.333333        0.750000       0.527778  0.694444  0.555556     0.638889   iz2ps\n",
      "3  0.529412   0.764706   0.588235        0.764706       0.441176  0.500000  0.441176     0.529412   1mpau\n",
      "4  0.666667   0.533333   0.466667        0.566667       0.600000  0.566667  0.633333     0.566667   7dwjy\n",
      "5  0.468750   0.656250   0.656250        0.781250       0.468750  0.593750  0.625000     0.468750   7swyk\n",
      "6  0.656250   0.625000   0.656250        0.625000       0.593750  0.468750  0.687500     0.625000   94mnx\n",
      "7  0.633333   0.633333   0.633333        0.566667       0.566667  0.566667  0.500000     0.600000   bd47a\n",
      "8  0.733333   0.733333   0.566667        0.766667       0.566667  0.633333  0.533333     0.600000   c24ur\n",
      "9  0.633333   0.866667   0.566667        0.700000       0.500000  0.600000  0.566667     0.533333   ctsax\n",
      "\n",
      "\n",
      "random_forest:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.458333   0.458333   0.541667        0.500000       0.458333  0.458333  0.375000     0.458333   62i9y\n",
      "1  0.617647   0.647059   0.264706        0.647059       0.676471  0.764706  0.647059     0.705882   2gu87\n",
      "2  0.638889   0.777778   0.444444        0.722222       0.750000  0.694444  0.583333     0.888889   iz2ps\n",
      "3  0.558824   0.764706   0.529412        0.647059       0.500000  0.529412  0.617647     0.588235   1mpau\n",
      "4  0.500000   0.566667   0.433333        0.533333       0.566667  0.533333  0.566667     0.533333   7dwjy\n",
      "5  0.562500   0.718750   0.562500        0.718750       0.593750  0.625000  0.562500     0.500000   7swyk\n",
      "6  0.593750   0.656250   0.750000        0.593750       0.593750  0.437500  0.625000     0.562500   94mnx\n",
      "7  0.533333   0.633333   0.533333        0.633333       0.566667  0.733333  0.533333     0.500000   bd47a\n",
      "8  0.533333   0.666667   0.633333        0.633333       0.433333  0.433333  0.500000     0.500000   c24ur\n",
      "9  0.733333   0.733333   0.566667        0.733333       0.666667  0.700000  0.700000     0.666667   ctsax\n",
      "\n",
      "\n",
      "naive_bayesian:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.625000   0.458333   0.375000        0.458333       0.750000  0.833333  0.625000     0.625000   62i9y\n",
      "1  0.382353   0.676471   0.294118        0.705882       0.500000  0.529412  0.470588     0.500000   2gu87\n",
      "2  0.305556   0.750000   0.388889        0.750000       0.500000  0.472222  0.444444     0.472222   iz2ps\n",
      "3  0.500000   0.823529   0.441176        0.823529       0.441176  0.500000  0.500000     0.470588   1mpau\n",
      "4  0.433333   0.466667   0.466667        0.466667       0.533333  0.533333  0.500000     0.466667   7dwjy\n",
      "5  0.687500   0.875000   0.406250        0.875000       0.718750  0.843750  0.687500     0.656250   7swyk\n",
      "6  0.500000   0.687500   0.531250        0.687500       0.531250  0.562500  0.500000     0.531250   94mnx\n",
      "7  0.400000   0.666667   0.466667        0.700000       0.533333  0.533333  0.600000     0.566667   bd47a\n",
      "8  0.466667   0.800000   0.666667        0.866667       0.433333  0.433333  0.633333     0.433333   c24ur\n",
      "9  0.666667   0.933333   0.566667        0.933333       0.566667  0.566667  0.666667     0.533333   ctsax\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.375000   0.541667   0.500000        0.500000       0.458333  0.458333  0.458333     0.416667   62i9y\n",
      "1  0.705882   0.676471   0.441176        0.617647       0.764706  0.588235  0.617647     0.558824   2gu87\n",
      "2  0.583333   0.722222   0.416667        0.666667       0.694444  0.722222  0.555556     0.694444   iz2ps\n",
      "3  0.588235   0.705882   0.647059        0.705882       0.529412  0.647059  0.647059     0.529412   1mpau\n",
      "4  0.566667   0.600000   0.500000        0.533333       0.600000  0.466667  0.600000     0.600000   7dwjy\n",
      "5  0.687500   0.843750   0.406250        0.562500       0.593750  0.687500  0.562500     0.593750   7swyk\n",
      "6  0.593750   0.687500   0.593750        0.593750       0.500000  0.593750  0.562500     0.531250   94mnx\n",
      "7  0.633333   0.666667   0.566667        0.700000       0.600000  0.666667  0.566667     0.600000   bd47a\n",
      "8  0.633333   0.800000   0.633333        0.733333       0.533333  0.533333  0.566667     0.633333   c24ur\n",
      "9  0.633333   0.666667   0.466667        0.666667       0.566667  0.500000  0.600000     0.600000   ctsax\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(classifier + \":\")\n",
    "#     print(pandas.DataFrame.from_dict(accuracies[classifier]))\n",
    "    # Using .to_string() gives nicer loooking results (doesn't split into new line)\n",
    "    print(pandas.DataFrame.from_dict(accuracies[classifier]).to_string())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37talos",
   "language": "python",
   "name": "py37talos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
