{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers - low vs high\n",
    "Exploring different classifiers with different autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of contents:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoders:  \n",
    "[Undercomplete Autoencoder](#Undercomplete-Autoencoder)  \n",
    "[Sparse Autoencoder](#Sparse-Autoencoder)  \n",
    "[Deep Autoencoder](#Deep-Autoencoder)  \n",
    "[Contractive Autoencoder](#Contractive-Autoencoder)  \n",
    "\n",
    "classifiers:  \n",
    "[Simple dense layer](#Simple-dense-layer)  \n",
    "[LSTM-based classifier](#LSTM-based-classifier)  \n",
    "[kNN](#kNN)  \n",
    "[SVC](#SVC)  \n",
    "[Random Forest](#Random-Forest)  \n",
    "[XGBoost](#XGBoost)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datareader # made by the previous author for reading the collected data\n",
    "import dataextractor # same as above\n",
    "import pandas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# need to disable eager execution for .get_weights() in contractive autoencoder loss to work\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "# required for the contractive autoencoder\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "\n",
    "import talos\n",
    "from talos.utils import lr_normalizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.set_floatx('float32') # call this, to set keras to use float32 to avoid a warning message\n",
    "metrics = ['accuracy']#,\n",
    "#            keras.metrics.TruePositives(),\n",
    "#            keras.metrics.FalsePositives(),\n",
    "#            keras.metrics.TrueNegatives(),\n",
    "#            keras.metrics.FalseNegatives()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/ageron/handson-ml/blob/master/extra_tensorflow_reproducibility.ipynb\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                        inter_op_parallelism_threads=1)\n",
    "\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    #... this will run single threaded\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(4)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the notebook in the terminal with \"PYTHONHASHSEED=0 jupyter notebook\" \n",
    "# or in anaconda \"set PYTHONHASHSEED=0\" then start jupyter notebook\n",
    "import os\n",
    "if os.environ.get(\"PYTHONHASHSEED\") != \"0\":\n",
    "    raise Exception(\"You must set PYTHONHASHSEED=0 when starting the Jupyter server to get reproducible results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is modfied original author's code for reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, x_train, y_train, batch_size, epochs, x_valid, y_valid, x_test, y_test):\n",
    "    \"\"\"Train model with the given training, validation, and test set, with appropriate batch size and # epochs.\"\"\"\n",
    "    epoch_data = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_valid, y_valid), verbose=0)\n",
    "    score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    acc = score[1]\n",
    "    score = score[0]\n",
    "    return score, acc, epoch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_complexities_timeframes_br_hb(path, ident, seconds):\n",
    "    \"\"\"Returns raw data along with task complexity class.\n",
    "    TODO: join functions. Add parameter to choose different task types and complexities\"\"\"\n",
    "\n",
    "    dataread = datareader.DataReader(path, ident)  # initialize path to data\n",
    "    data = dataread.read_grc_data()  # read from files\n",
    "    samp_rate = int(round(len(data[1]) / max(data[0])))\n",
    "    cog_res = dataread.read_cognitive_load_study(str(ident) + '-primary-extract.txt')\n",
    "\n",
    "    tasks_data = np.empty((0, seconds*samp_rate))\n",
    "    tasks_y = np.empty((0, 1))\n",
    "    breathing = np.empty((0,12))\n",
    "    heartbeat = np.empty((0,10))\n",
    "\n",
    "    busy_n = dataread.get_data_task_timestamps(return_indexes=True)\n",
    "    \n",
    "    for i in cog_res['task_number']:\n",
    "        task_num_table = i - 225  # 0 - 17\n",
    "        tmp_tasks_data = np.empty((0, seconds*samp_rate))\n",
    "        tmp_tasks_y = np.empty((0, 1))\n",
    "        tmp_breathing = np.empty((0,12))\n",
    "        tmp_heartbeat = np.empty((0,10))\n",
    "        \n",
    "        ### task complexity classification\n",
    "        if cog_res['task_complexity'][task_num_table] == 'medium':\n",
    "            continue\n",
    "        # if cog_res['task_label'][task_num_table] == 'FA' or cog_res['task_label'][task_num_table] == 'HP':\n",
    "        #     continue\n",
    "#         if cog_res['task_label'][task_num_table] != 'NC':\n",
    "#             continue\n",
    "            \n",
    "        map_compl = {\n",
    "            'low': 0,\n",
    "            'medium': 2,\n",
    "            'high': 1\n",
    "        }\n",
    "        for j in range(10):\n",
    "            new_end = int(busy_n[task_num_table][1] - j * samp_rate)\n",
    "            new_start = int(new_end - samp_rate*30)\n",
    "            dataextract = dataextractor.DataExtractor(data[0][new_start:new_end],\n",
    "                                                      data[1][new_start:new_end], samp_rate)\n",
    "            # get extracted features for breathing\n",
    "            tmpBR = dataextract.extract_from_breathing_time(data[0][new_start:new_end],\n",
    "                                                                 data[1][new_start:new_end])\n",
    "            #get extracted features for heartbeat\n",
    "            tmpHB = dataextract.extract_from_heartbeat_time(data[0][new_start:new_end],\n",
    "                                                                 data[1][new_start:new_end])\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                tmp_tasks_data = np.vstack((tmp_tasks_data, dataextract.y[-samp_rate * seconds:]))\n",
    "                tmp_tasks_y = np.vstack((tmp_tasks_y, map_compl.get(cog_res['task_complexity'][task_num_table])))\n",
    "\n",
    "                tmp_breathing = np.vstack((tmp_breathing, tmpBR.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "                tmp_heartbeat = np.vstack((tmp_heartbeat, tmpHB.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "                \n",
    "            except ValueError:\n",
    "#                 print(ident)\n",
    "                continue\n",
    "\n",
    "            tasks_data = np.vstack((tasks_data, dataextract.y))\n",
    "            tasks_y = np.vstack((tasks_y, map_compl.get(cog_res['task_complexity'][task_num_table])))\n",
    "            breathing = np.vstack((breathing, tmpBR.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "            heartbeat = np.vstack((heartbeat, tmpHB.to_numpy(dtype='float64', na_value=0)[0][:-1]))\n",
    "            \n",
    "    return tasks_data, tasks_y, breathing, heartbeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_idents_br_hb(path, idents, seconds):\n",
    "    \"\"\"Go through all user data and take out windows of only <seconds> long time frames,\n",
    "    along with the given class (from 'divide_each_task' function).\n",
    "    \"\"\"\n",
    "    samp_rate = 43  # hard-coded sample rate\n",
    "    data, ys = np.empty((0, samp_rate*seconds)), np.empty((0, 1))\n",
    "    brs = np.empty((0,12))\n",
    "    hbs = np.empty((0,10))\n",
    "    combined = np.empty((0,22))\n",
    "    \n",
    "    # was gettign some weird warnings; stack overflow said to ignore them\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        for i in idents:\n",
    "            #x, y, br, hb = get_busy_vs_relax_timeframes_br_hb(path, i, seconds) # either 'get_busy_vs_relax_timeframes',\n",
    "            # get_engagement_increase_vs_decrease_timeframes, get_task_complexities_timeframes or get_TLX_timeframes\n",
    "            x, y, br, hb = get_task_complexities_timeframes_br_hb(path, i, seconds)\n",
    "            \n",
    "            data = np.vstack((data, x))\n",
    "            ys = np.vstack((ys, y))\n",
    "            brs = np.vstack((brs, br))\n",
    "            hbs = np.vstack((hbs, hb))\n",
    "        combined = np.hstack((brs,hbs))\n",
    "    \n",
    "    return data, ys, brs, hbs, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(x, standardScaler=True, minMaxScaler=True):\n",
    "    \n",
    "    if standardScaler:\n",
    "        # Scale with standard scaler\n",
    "        sscaler = StandardScaler()\n",
    "        sscaler.fit(x)\n",
    "        x = sscaler.transform(x)\n",
    "\n",
    "    if minMaxScaler:\n",
    "        # Scale with MinMax to range [0,1]\n",
    "        mmscaler = MinMaxScaler((0,1))\n",
    "        mmscaler.fit(x)\n",
    "        x = mmscaler.transform(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accs is a dictionary which holds 1d arrays of accuracies in each key\n",
    "# except the key 'test id' which holds strings of the id which yielded the coresponding accuracies\n",
    "def print_accs_stats(accs):\n",
    "    \n",
    "    printDict = {}\n",
    "    # loop over each key\n",
    "    for key in accs:\n",
    "    \n",
    "        if (key == 'test id'):\n",
    "            # skip calculating ids\n",
    "            continue\n",
    "        printDict[key] = {}\n",
    "        tmpDict = printDict[key]\n",
    "        # calculate and print some statistics\n",
    "        tmpDict['min'] = np.min(accs[key])\n",
    "        tmpDict['max'] = np.max(accs[key])\n",
    "        tmpDict['mean'] = np.mean(accs[key])\n",
    "        tmpDict['median'] = np.median(accs[key])\n",
    "    \n",
    "    print(pandas.DataFrame.from_dict(printDict).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds():\n",
    "    # clear session and set seeds again\n",
    "    # cannot clear session due to tf.compat.v1 graphs, but add tf.compat.v1.set_random_seed\n",
    "#     K.clear_session()\n",
    "    tf.compat.v1.set_random_seed(2)\n",
    "    random.seed(1)\n",
    "    np.random.seed(4)\n",
    "    tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undercomplete Autoencoder  \n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undercomplete_ae(x, encoding_dim=64, encoded_as_model=False):\n",
    "    # Simplest possible autoencoder from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_data = Input(shape=x[0].shape, name=\"input\")\n",
    "    dropout = Dropout(0.25, name=\"dropout\")(input_data)\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='relu', name=\"encoded\")(dropout)\n",
    "    \n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(x[0].shape[0], activation='sigmoid', name=\"decoded\")(encoded)\n",
    "\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "    \n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Autoencoder  \n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_ae(x, encoding_dim=64, encoded_as_model=False):\n",
    "    # Simplest possible autoencoder from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_data = Input(shape=x[0].shape, name=\"input\")\n",
    "    dropout = Dropout(0.25, name=\"dropout\") (input_data)\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    # add a sparsity constraint\n",
    "    encoded = Dense(encoding_dim, activation='relu', name=\"encoded\",\n",
    "                    activity_regularizer=regularizers.l1(10e-5))(dropout)\n",
    "    \n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(x[0].shape[0], activation='sigmoid', name=\"decoded\")(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_data, decoded, name=\"sparse_ae\")\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "    \n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Autoencoder  \n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_ae(x, enc_layers=[512,256], encoding_dim=64, dec_layers=[256,512], encoded_as_model=False):\n",
    "    # From https://www.tensorflow.org/guide/keras/functional#use_the_same_graph_of_layers_to_define_multiple_models\n",
    "    input_data = keras.Input(shape=x[0].shape, name=\"normalized_signal\")\n",
    "    model = Dropout(0.25, name=\"dropout\", autocast=False)(input_data)\n",
    "    for i in enumerate(enc_layers):\n",
    "        model = Dense(i[1], activation=\"relu\", name=\"dense_enc_\" + str(i[0]+1))(model)\n",
    "    encoded_output = Dense(encoding_dim, activation=\"relu\", name=\"encoded_signal\")(model)\n",
    "\n",
    "    encoded = encoded_output\n",
    "\n",
    "    model = layers.Dense(dec_layers[0], activation=\"sigmoid\", name=\"dense_dec_1\")(encoded_output)\n",
    "    for i in enumerate(dec_layers[1:]):\n",
    "        model = Dense(i[1], activation=\"sigmoid\", name=\"dense_dec_\" + str(i[0]+2))(model)\n",
    "    decoded_output = Dense(x[0].shape[0], activation=\"sigmoid\", name=\"reconstructed_signal\")(model)\n",
    "    \n",
    "    autoencoder = Model(input_data, decoded_output, name=\"autoencoder\")\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "\n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contractive Autoencoder\n",
    "From: https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to be able to access the autoencoder in the loss funciton\n",
    "def loss_with_params(autoencoder):\n",
    "    # loss function from https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/\n",
    "    def contractive_loss(y_pred, y_true):\n",
    "\n",
    "        lam = 1e-4\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "\n",
    "        W = K.variable(value=autoencoder.get_layer('encoded').get_weights()[0])  # N x N_hidden\n",
    "        W = K.transpose(W)  # N_hidden x N\n",
    "        h = autoencoder.get_layer('encoded').output\n",
    "        dh = h * (1 - h)  # N_batch x N_hidden\n",
    "\n",
    "        # N_batch x N_hidden * N_hidden x 1 = N_batch x 1\n",
    "        contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "        return mse + contractive\n",
    "    return contractive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractive_ae(x, encoding_dim=64, encoded_as_model=False):\n",
    "    # From https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/\n",
    "\n",
    "    input_data = Input(shape=x[0].shape, name=\"input\")\n",
    "    encoded = Dense(encoding_dim, activation='sigmoid', name='encoded')(input_data)\n",
    "    outputs = Dense(x[0].shape[0], activation='linear', name=\"output\")(encoded)\n",
    "\n",
    "    autoencoder = Model(input_data, outputs, name=\"autoencoder\")\n",
    "    \n",
    "    # compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss=loss_with_params(autoencoder), metrics=metrics)\n",
    "    \n",
    "    # if return encoder in the encoded variable\n",
    "    if encoded_as_model:\n",
    "        encoded = Model(input_data, encoded)\n",
    "    \n",
    "    return autoencoder, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary to store accuracies for comparison\n",
    "accuracies = {}\n",
    "\n",
    "# used for reading the data into an array\n",
    "seconds = 30  # time window length\n",
    "idents = ['2gu87', 'iz2ps', '1mpau', '7dwjy', '7swyk', '94mnx', 'bd47a', 'c24ur', 'ctsax', 'dkhty', 'e4gay',\n",
    "              'ef5rq', 'f1gjp', 'hpbxa', 'pmyfl', 'r89k1', 'tn4vl', 'td5pr', 'gyqu9', 'fzchw', 'l53hg', '3n2f9',\n",
    "              '62i9y']\n",
    "path = '../../../StudyData/'\n",
    "\n",
    "# change to len(idents) at the end to use all the data\n",
    "n = 7 #len(idents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper loop function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper loop funciton for the sklearn and XGBoost classifiers\n",
    "def helper_loop(classifier_function, idents, n=5):\n",
    "    #returns a dictionary with accuracies\n",
    "\n",
    "    # set the variables in the dictionary\n",
    "    accs = {}\n",
    "    accs['phase'] = []\n",
    "    accs['breathing'] = []\n",
    "    accs['heartbeat'] = []\n",
    "    accs['combined br hb'] = []\n",
    "    accs['undercomplete'] = []\n",
    "    accs['sparse'] = []\n",
    "    accs['deep'] = []\n",
    "    accs['contractive'] = []\n",
    "    accs['test id'] = []\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    with tf.compat.v1.Session(config=config) as sess:\n",
    "        # leave out person out validation\n",
    "        for i in range(n):\n",
    "\n",
    "            # print current iteration and time elapsed from start\n",
    "            print(\"iteration:\", i+1, \"of\", n, \"; time elapsed:\", datetime.now()-start_time)\n",
    "\n",
    "            ## ----- Data preparation:\n",
    "            validation_idents = [idents[i]]\n",
    "            test_idents = [idents[i-1]]\n",
    "\n",
    "            train_idents = []\n",
    "            for ident in idents:\n",
    "                if (ident not in test_idents) and (ident not in validation_idents):\n",
    "                    train_idents.append(ident)\n",
    "\n",
    "            # save test id to see which id yielded which accuracies\n",
    "            accs['test id'].append(test_idents[0])\n",
    "\n",
    "            # Load data (xt-raw phase data, y-class, br-breathing data, hb-heartbeat data, cmb-combined [br,hb])\n",
    "            xt_train, y_train, br_train, hb_train, cmb_train = get_data_from_idents_br_hb(path, train_idents, seconds)\n",
    "            xt_valid, y_valid, br_valid, hb_valid, cmb_valid = get_data_from_idents_br_hb(path, validation_idents, seconds)\n",
    "            xt_test, y_test, br_test, hb_test, cmb_test = get_data_from_idents_br_hb(path, test_idents, seconds)\n",
    "\n",
    "            # change the y arrays to flat 1d arrays\n",
    "            y_train = y_train.ravel()\n",
    "            y_valid = y_valid.ravel()\n",
    "            y_test = y_test.ravel()\n",
    "            \n",
    "            # Scale data with standard scaler then MinMax scaler\n",
    "            # Raw Phase data:\n",
    "            xt_train = scale_data(xt_train, standardScaler=True, minMaxScaler=True)\n",
    "            xt_valid = scale_data(xt_valid, standardScaler=True, minMaxScaler=True)\n",
    "            xt_test = scale_data(xt_test, standardScaler=True, minMaxScaler=True)\n",
    "            # Hand extracted breathing data:\n",
    "            br_train = scale_data(br_train, standardScaler=True, minMaxScaler=True)\n",
    "            br_valid = scale_data(br_valid, standardScaler=True, minMaxScaler=True)\n",
    "            br_test = scale_data(br_test, standardScaler=True, minMaxScaler=True)\n",
    "            # Hand extracted Heartbeat data:\n",
    "            hb_train = scale_data(hb_train, standardScaler=True, minMaxScaler=True)\n",
    "            hb_valid = scale_data(hb_valid, standardScaler=True, minMaxScaler=True)\n",
    "            hb_test = scale_data(hb_test, standardScaler=True, minMaxScaler=True)\n",
    "            # Combined breathing and heartbeat data (joined together into one matrix)\n",
    "            cmb_train = scale_data(cmb_train, standardScaler=True, minMaxScaler=True)\n",
    "            cmb_valid = scale_data(cmb_valid, standardScaler=True, minMaxScaler=True)\n",
    "            cmb_test = scale_data(cmb_test, standardScaler=True, minMaxScaler=True)\n",
    "\n",
    "            \n",
    "\n",
    "            ## ----- Classify without autoencoders:\n",
    "            # Phase classifier:\n",
    "            set_random_seeds()\n",
    "            model = classifier_function()\n",
    "            model.fit(xt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xt_test) == y_test) / len(y_test)\n",
    "            accs['phase'].append(curr_acc)\n",
    "            \n",
    "            # Breathing classifier:\n",
    "            set_random_seeds()\n",
    "            base_model = classifier_function()\n",
    "            base_model.fit(br_train, y_train)\n",
    "            curr_acc = np.sum(base_model.predict(br_test) == y_test) / len(y_test)\n",
    "            accs['breathing'].append(curr_acc)\n",
    "\n",
    "            # Heartbeat classifier:\n",
    "            set_random_seeds()\n",
    "            base_model = classifier_function()\n",
    "            base_model.fit(hb_train, y_train)\n",
    "            curr_acc = np.sum(base_model.predict(hb_test) == y_test) / len(y_test)\n",
    "            accs['heartbeat'].append(curr_acc)\n",
    "\n",
    "            # Combined classifier:\n",
    "            set_random_seeds()\n",
    "            base_model = classifier_function()\n",
    "            base_model.fit(cmb_train, y_train)\n",
    "            curr_acc = np.sum(base_model.predict(cmb_test) == y_test) / len(y_test)\n",
    "            accs['combined br hb'].append(curr_acc)\n",
    "\n",
    "\n",
    "\n",
    "            ## ----- Classify with autoencoders:\n",
    "            # AE Training params\n",
    "            batch_size = 256\n",
    "            epochs = 100\n",
    "            encoding_dim = 64\n",
    "\n",
    "            # undercomplete AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = undercomplete_ae(xt_train, encoding_dim, encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['undercomplete'].append(curr_acc)\n",
    "\n",
    "            # sparse AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = sparse_ae(xt_train, encoding_dim, encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['sparse'].append(curr_acc)\n",
    "\n",
    "            # deep AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = deep_ae(xt_train, enc_layers=[512,256], encoding_dim=encoding_dim, dec_layers=[256,512], encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['deep'].append(curr_acc)\n",
    "\n",
    "            # contractive AE\n",
    "            set_random_seeds()\n",
    "            autoencoder, encoded = contractive_ae(xt_train, encoding_dim, encoded_as_model=True)\n",
    "            sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                                   xt_valid, xt_valid, xt_test, xt_test)\n",
    "            model = classifier_function()\n",
    "            xtt_train = encoded.predict(xt_train)\n",
    "            xtt_test = encoded.predict(xt_test)\n",
    "            model.fit(xtt_train, y_train)\n",
    "            curr_acc = np.sum(model.predict(xtt_test) == y_test) / len(y_test)\n",
    "            accs['contractive'].append(curr_acc)\n",
    "\n",
    "    # Print total time required to run this\n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Completed!\", \"Time elapsed:\", elapsed_time)\n",
    "    \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def KNN_classifier():\n",
    "    model = KNeighborsClassifier(p=3, n_neighbors=7, metric='cosine')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00\n",
      "WARNING:tensorflow:From D:\\Miscellanious\\Anaconda\\envs\\py37talos\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "iteration: 2 of 7 ; time elapsed: 0:02:13.982688\n",
      "iteration: 3 of 7 ; time elapsed: 0:04:21.032716\n",
      "iteration: 4 of 7 ; time elapsed: 0:06:37.722013\n",
      "iteration: 5 of 7 ; time elapsed: 0:09:00.387753\n",
      "iteration: 6 of 7 ; time elapsed: 0:11:33.011195\n",
      "iteration: 7 of 7 ; time elapsed: 0:14:21.043605\n",
      "Completed! Time elapsed: 0:17:12.994278\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(KNN_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['kNN'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.458333   0.408333   0.575000        0.525000       0.550000  0.391667   \n",
       "1  0.658333   0.400000   0.583333        0.458333       0.541667  0.525000   \n",
       "2  0.575000   0.441667   0.583333        0.475000       0.558333  0.466667   \n",
       "3  0.541667   0.608333   0.491667        0.541667       0.541667  0.508333   \n",
       "4  0.558333   0.550000   0.541667        0.683333       0.525000  0.491667   \n",
       "5  0.391667   0.541667   0.575000        0.425000       0.508333  0.475000   \n",
       "6  0.700000   0.575000   0.458333        0.416667       0.683333  0.608333   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.475000     0.525000   62i9y  \n",
       "1  0.575000     0.558333   2gu87  \n",
       "2  0.516667     0.583333   iz2ps  \n",
       "3  0.466667     0.483333   1mpau  \n",
       "4  0.416667     0.433333   7dwjy  \n",
       "5  0.641667     0.475000   7swyk  \n",
       "6  0.608333     0.691667   94mnx  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.391667   0.400000   0.458333        0.416667       0.508333  0.391667  0.416667     0.433333\n",
      "max     0.700000   0.608333   0.583333        0.683333       0.683333  0.608333  0.641667     0.691667\n",
      "mean    0.554762   0.503571   0.544048        0.503571       0.558333  0.495238  0.528571     0.535714\n",
      "median  0.558333   0.541667   0.575000        0.475000       0.541667  0.491667  0.516667     0.525000\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def SVC_classifier():\n",
    "    model = SVC(kernel='rbf', C=1.5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00.005983\n",
      "iteration: 2 of 7 ; time elapsed: 0:03:01.461545\n",
      "iteration: 3 of 7 ; time elapsed: 0:06:04.339267\n",
      "iteration: 4 of 7 ; time elapsed: 0:09:11.219051\n",
      "iteration: 5 of 7 ; time elapsed: 0:12:22.639876\n",
      "iteration: 6 of 7 ; time elapsed: 0:15:35.612219\n",
      "iteration: 7 of 7 ; time elapsed: 0:18:47.217661\n",
      "Completed! Time elapsed: 0:22:08.072677\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(SVC_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['SVC'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.300000   0.491667   0.500000        0.441667       0.416667  0.491667   \n",
       "1  0.433333   0.450000   0.516667        0.516667       0.508333  0.491667   \n",
       "2  0.533333   0.308333   0.500000        0.408333       0.500000  0.483333   \n",
       "3  0.616667   0.516667   0.500000        0.458333       0.483333  0.516667   \n",
       "4  0.475000   0.441667   0.500000        0.533333       0.425000  0.491667   \n",
       "5  0.558333   0.608333   0.500000        0.500000       0.583333  0.550000   \n",
       "6  0.575000   0.650000   0.441667        0.633333       0.625000  0.625000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.375000     0.466667   62i9y  \n",
       "1  0.508333     0.541667   2gu87  \n",
       "2  0.550000     0.558333   iz2ps  \n",
       "3  0.516667     0.533333   1mpau  \n",
       "4  0.466667     0.433333   7dwjy  \n",
       "5  0.616667     0.533333   7swyk  \n",
       "6  0.616667     0.691667   94mnx  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.300000   0.308333   0.441667        0.408333       0.416667  0.483333  0.375000     0.433333\n",
      "max     0.616667   0.650000   0.516667        0.633333       0.625000  0.625000  0.616667     0.691667\n",
      "mean    0.498810   0.495238   0.494048        0.498810       0.505952  0.521429  0.521429     0.536905\n",
      "median  0.533333   0.491667   0.500000        0.500000       0.500000  0.491667  0.516667     0.533333\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def random_forest_classifier():\n",
    "    model = RandomForestClassifier(n_estimators = 250,\n",
    "                                     min_samples_split = 10,\n",
    "                                     min_samples_leaf = 4,\n",
    "                                     max_features = 'auto',\n",
    "                                     max_depth = 90,\n",
    "                                     bootstrap = True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00.005985\n",
      "iteration: 2 of 7 ; time elapsed: 0:03:26.966782\n",
      "iteration: 3 of 7 ; time elapsed: 0:06:55.113636\n",
      "iteration: 4 of 7 ; time elapsed: 0:10:20.153873\n",
      "iteration: 5 of 7 ; time elapsed: 0:13:48.013152\n",
      "iteration: 6 of 7 ; time elapsed: 0:17:18.545559\n",
      "iteration: 7 of 7 ; time elapsed: 0:20:56.114613\n",
      "Completed! Time elapsed: 0:24:36.162203\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(random_forest_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['random_forest'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.391667   0.450000   0.491667        0.441667       0.300000  0.391667   \n",
       "1  0.400000   0.483333   0.433333        0.591667       0.416667  0.450000   \n",
       "2  0.350000   0.525000   0.425000        0.600000       0.441667  0.466667   \n",
       "3  0.500000   0.325000   0.375000        0.208333       0.458333  0.533333   \n",
       "4  0.350000   0.700000   0.466667        0.575000       0.408333  0.541667   \n",
       "5  0.625000   0.450000   0.516667        0.575000       0.633333  0.458333   \n",
       "6  0.516667   0.575000   0.558333        0.466667       0.558333  0.525000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.333333     0.325000   62i9y  \n",
       "1  0.508333     0.383333   2gu87  \n",
       "2  0.533333     0.550000   iz2ps  \n",
       "3  0.466667     0.466667   1mpau  \n",
       "4  0.358333     0.450000   7dwjy  \n",
       "5  0.516667     0.450000   7swyk  \n",
       "6  0.558333     0.566667   94mnx  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.350000   0.325000   0.375000        0.208333       0.300000  0.391667  0.333333     0.325000\n",
      "max     0.625000   0.700000   0.558333        0.600000       0.633333  0.541667  0.558333     0.566667\n",
      "mean    0.447619   0.501190   0.466667        0.494048       0.459524  0.480952  0.467857     0.455952\n",
      "median  0.400000   0.483333   0.466667        0.575000       0.441667  0.466667  0.508333     0.450000\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "def naive_bayesian_classifier():\n",
    "    model = ComplementNB()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00.004987\n",
      "iteration: 2 of 7 ; time elapsed: 0:03:21.865217\n",
      "iteration: 3 of 7 ; time elapsed: 0:06:46.331717\n",
      "iteration: 4 of 7 ; time elapsed: 0:10:09.513734\n",
      "iteration: 5 of 7 ; time elapsed: 0:13:42.550339\n",
      "iteration: 6 of 7 ; time elapsed: 0:17:17.386563\n",
      "iteration: 7 of 7 ; time elapsed: 0:21:05.037112\n",
      "Completed! Time elapsed: 0:24:49.152310\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(naive_bayesian_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['naive_bayesian'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.475000   0.558333   0.491667        0.500000       0.416667  0.391667   \n",
       "1  0.600000   0.633333   0.600000        0.616667       0.566667  0.633333   \n",
       "2  0.516667   0.358333   0.425000        0.375000       0.600000  0.541667   \n",
       "3  0.641667   0.150000   0.541667        0.225000       0.450000  0.433333   \n",
       "4  0.566667   0.466667   0.358333        0.466667       0.558333  0.416667   \n",
       "5  0.525000   0.383333   0.500000        0.400000       0.566667  0.541667   \n",
       "6  0.725000   0.475000   0.541667        0.483333       0.700000  0.725000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.466667     0.375000   62i9y  \n",
       "1  0.608333     0.533333   2gu87  \n",
       "2  0.516667     0.500000   iz2ps  \n",
       "3  0.550000     0.491667   1mpau  \n",
       "4  0.516667     0.541667   7dwjy  \n",
       "5  0.416667     0.416667   7swyk  \n",
       "6  0.750000     0.733333   94mnx  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.475000   0.150000   0.358333        0.225000       0.416667  0.391667  0.416667     0.375000\n",
      "max     0.725000   0.633333   0.600000        0.616667       0.700000  0.725000  0.750000     0.733333\n",
      "mean    0.578571   0.432143   0.494048        0.438095       0.551190  0.526190  0.546429     0.513095\n",
      "median  0.566667   0.466667   0.500000        0.466667       0.566667  0.541667  0.516667     0.500000\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def XGBoost_classifier():\n",
    "    model = XGBClassifier(n_estimators = 83)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00.003991\n",
      "iteration: 2 of 7 ; time elapsed: 0:03:43.053825\n",
      "iteration: 3 of 7 ; time elapsed: 0:07:31.586255\n",
      "iteration: 4 of 7 ; time elapsed: 0:11:29.039808\n",
      "iteration: 5 of 7 ; time elapsed: 0:15:32.849651\n",
      "iteration: 6 of 7 ; time elapsed: 0:19:43.020015\n",
      "iteration: 7 of 7 ; time elapsed: 0:23:58.714797\n",
      "Completed! Time elapsed: 0:28:18.182285\n"
     ]
    }
   ],
   "source": [
    "accs = helper_loop(XGBoost_classifier, idents, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['XGBoost'] = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.383333   0.558333   0.458333        0.500000       0.383333  0.325000   \n",
       "1  0.450000   0.558333   0.541667        0.583333       0.408333  0.416667   \n",
       "2  0.416667   0.408333   0.550000        0.491667       0.541667  0.500000   \n",
       "3  0.516667   0.400000   0.441667        0.125000       0.475000  0.500000   \n",
       "4  0.416667   0.650000   0.500000        0.408333       0.408333  0.425000   \n",
       "5  0.533333   0.516667   0.550000        0.525000       0.550000  0.591667   \n",
       "6  0.533333   0.633333   0.391667        0.616667       0.583333  0.566667   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.575000     0.375000   62i9y  \n",
       "1  0.491667     0.483333   2gu87  \n",
       "2  0.475000     0.425000   iz2ps  \n",
       "3  0.483333     0.550000   1mpau  \n",
       "4  0.416667     0.408333   7dwjy  \n",
       "5  0.616667     0.425000   7swyk  \n",
       "6  0.508333     0.625000   94mnx  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.383333   0.400000   0.391667        0.125000       0.383333  0.325000  0.416667     0.375000\n",
      "max     0.533333   0.650000   0.550000        0.616667       0.583333  0.591667  0.616667     0.625000\n",
      "mean    0.464286   0.532143   0.490476        0.464286       0.478571  0.475000  0.509524     0.470238\n",
      "median  0.450000   0.558333   0.500000        0.500000       0.475000  0.500000  0.491667     0.425000\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(model, params):\n",
    "    \n",
    "    model = Dropout(params['dropout'], name='dropout_cl')(model)\n",
    "    model = Dense(params['hidden_size'], activation=params['activation'], name='dense_cl1')(model)\n",
    "    model = Dense(1, activation=params['last_activation'], name='dense_cl2')(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier_base():\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dropout': 0.24,\n",
    "    'optimizer': 'Adam',\n",
    "    'hidden_size': 32,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'last_activation': 'sigmoid',\n",
    "    'activation': 'softmax',\n",
    "    'batch_size': 256,\n",
    "    'epochs': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00.006955\n",
      "iteration: 2 of 7 ; time elapsed: 0:06:49.061160\n",
      "iteration: 3 of 7 ; time elapsed: 0:14:07.304875\n",
      "iteration: 4 of 7 ; time elapsed: 0:21:44.615280\n",
      "iteration: 5 of 7 ; time elapsed: 0:29:45.350013\n",
      "iteration: 6 of 7 ; time elapsed: 0:38:13.286252\n",
      "iteration: 7 of 7 ; time elapsed: 0:47:02.862003\n",
      "Completed! Time elapsed: 0:56:22.299823\n"
     ]
    }
   ],
   "source": [
    "# set the variables in the dictionary\n",
    "accuracies['simple_dense'] = {}\n",
    "accs = accuracies['simple_dense']\n",
    "accs['phase'] = []\n",
    "accs['breathing'] = []\n",
    "accs['heartbeat'] = []\n",
    "accs['combined br hb'] = []\n",
    "accs['undercomplete'] = []\n",
    "accs['sparse'] = []\n",
    "accs['deep'] = []\n",
    "accs['contractive'] = []\n",
    "accs['test id'] = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # leave out person out validation\n",
    "    for i in range(n):\n",
    "\n",
    "        # print current iteration and time elapsed from start\n",
    "        print(\"iteration:\", i+1, \"of\", n, \"; time elapsed:\", datetime.now()-start_time)\n",
    "\n",
    "        ## ----- Data preparation:\n",
    "        validation_idents = [idents[i]]\n",
    "        test_idents = [idents[i-1]]\n",
    "\n",
    "        train_idents = []\n",
    "        for ident in idents:\n",
    "            if (ident not in test_idents) and (ident not in validation_idents):\n",
    "                train_idents.append(ident)\n",
    "        \n",
    "        # save test id to see which id yielded which accuracies\n",
    "        accs['test id'].append(test_idents[0])\n",
    "\n",
    "        # Load data (xt-raw phase data, y-class, br-breathing data, hb-heartbeat data, cmb-combined [br,hb])\n",
    "        xt_train, y_train, br_train, hb_train, cmb_train = get_data_from_idents_br_hb(path, train_idents, seconds)\n",
    "        xt_valid, y_valid, br_valid, hb_valid, cmb_valid = get_data_from_idents_br_hb(path, validation_idents, seconds)\n",
    "        xt_test, y_test, br_test, hb_test, cmb_test = get_data_from_idents_br_hb(path, test_idents, seconds)\n",
    "\n",
    "        # Scale data with standard scaler then MinMax scaler\n",
    "        # Raw Phase data:\n",
    "        xt_train = scale_data(xt_train, standardScaler=True, minMaxScaler=True)\n",
    "        xt_valid = scale_data(xt_valid, standardScaler=True, minMaxScaler=True)\n",
    "        xt_test = scale_data(xt_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted breathing data:\n",
    "        br_train = scale_data(br_train, standardScaler=True, minMaxScaler=True)\n",
    "        br_valid = scale_data(br_valid, standardScaler=True, minMaxScaler=True)\n",
    "        br_test = scale_data(br_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted Heartbeat data:\n",
    "        hb_train = scale_data(hb_train, standardScaler=True, minMaxScaler=True)\n",
    "        hb_valid = scale_data(hb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        hb_test = scale_data(hb_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Combined breathing and heartbeat data (joined together into one matrix)\n",
    "        cmb_train = scale_data(cmb_train, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_valid = scale_data(cmb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_test = scale_data(cmb_test, standardScaler=True, minMaxScaler=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## ----- Classify without autoencoders:\n",
    "        # Phase classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['phase'].append(curr_acc)\n",
    "\n",
    "        # Breathing classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, br_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               br_valid, y_valid, br_test, y_test)\n",
    "        accs['breathing'].append(curr_acc)\n",
    "\n",
    "        # Heartbeat classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, hb_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               hb_valid, y_valid, hb_test, y_test)\n",
    "        accs['heartbeat'].append(curr_acc)\n",
    "\n",
    "        # Combined classifier:\n",
    "        model = dense_classifier_base()\n",
    "        sc, curr_acc, epoch_data = model_train(model, cmb_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               cmb_valid, y_valid, cmb_test, y_test)\n",
    "        accs['combined br hb'].append(curr_acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## ----- Classify with autoencoders:\n",
    "        # AE Training params\n",
    "        batch_size = 256\n",
    "        epochs = 100\n",
    "        encoding_dim = 64\n",
    "\n",
    "        # Undercomplete AE:\n",
    "        autoencoder, encoded = undercomplete_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['undercomplete'].append(curr_acc)\n",
    "\n",
    "        # Sparse AE:\n",
    "        autoencoder, encoded = sparse_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['sparse'].append(curr_acc)\n",
    "\n",
    "        # Deep AE:\n",
    "        autoencoder, encoded = deep_ae(xt_train, enc_layers=[512,256], encoding_dim=encoding_dim, dec_layers=[256,512])\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['deep'].append(curr_acc)\n",
    "\n",
    "        # Contractive AE:\n",
    "        autoencoder, encoded = contractive_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = dense_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['contractive'].append(curr_acc)\n",
    "\n",
    "# Print total time required to run this\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Completed!\", \"Time elapsed:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7swyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>94mnx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.425000   0.625000   0.500000        0.516667       0.516667  0.466667   \n",
       "1  0.641667   0.658333   0.541667        0.616667       0.516667  0.541667   \n",
       "2  0.500000   0.316667   0.391667        0.433333       0.483333  0.475000   \n",
       "3  0.408333   0.225000   0.491667        0.458333       0.583333  0.608333   \n",
       "4  0.558333   0.525000   0.500000        0.466667       0.625000  0.433333   \n",
       "5  0.425000   0.241667   0.558333        0.366667       0.441667  0.358333   \n",
       "6  0.633333   0.566667   0.500000        0.566667       0.608333  0.650000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.300000     0.525000   62i9y  \n",
       "1  0.616667     0.591667   2gu87  \n",
       "2  0.541667     0.483333   iz2ps  \n",
       "3  0.558333     0.575000   1mpau  \n",
       "4  0.583333     0.550000   7dwjy  \n",
       "5  0.475000     0.500000   7swyk  \n",
       "6  0.658333     0.666667   94mnx  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.408333   0.225000   0.391667        0.366667       0.441667  0.358333  0.300000     0.483333\n",
      "max     0.641667   0.658333   0.558333        0.616667       0.625000  0.650000  0.658333     0.666667\n",
      "mean    0.513095   0.451190   0.497619        0.489286       0.539286  0.504762  0.533333     0.555952\n",
      "median  0.500000   0.525000   0.500000        0.466667       0.516667  0.475000  0.558333     0.550000\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM-based classifier  \n",
    "based on the original author's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize hyperparameters with talos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_classifier(model, params):\n",
    "\n",
    "    model = layers.Reshape((-1, 1), input_shape=(model.shape), name='reshape_cl') (model)\n",
    "\n",
    "    model = layers.Dropout(params['dropout'], name='dropout_cl1') (model)\n",
    "    \n",
    "    model = Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides'],\n",
    "                     name='conv1d_cl1') (model)\n",
    "    \n",
    "    model = MaxPooling1D(pool_size=params['pool_size'], name='maxpool_cl1') (model)\n",
    "    \n",
    "    model = Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides'],\n",
    "                     name='conv1d_cl2') (model)\n",
    "    \n",
    "    model = MaxPooling1D(pool_size=params['pool_size'], name='maxpool_cl2') (model)\n",
    "    \n",
    "    model = layers.Dropout(params['dropout'], name='dropout_cl2') (model)\n",
    "\n",
    "    model = LSTM(params['lstm_output_size'], activation='sigmoid', name='lstm_cl') (model)\n",
    "\n",
    "    model = Dense(1, activation=params['last_activation'], name='dense_cl') (model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_classifier_base(params):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides']))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=params['pool_size']))\n",
    "    model.add(Conv1D(params['filters'],\n",
    "                     params['kernel_size'],\n",
    "                     padding='valid',\n",
    "                     activation=params['activation'],\n",
    "                     strides=params['strides']))\n",
    "    model.add(MaxPooling1D(pool_size=params['pool_size']))\n",
    "\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(LSTM(params['lstm_output_size']))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(params['last_activation']))\n",
    "\n",
    "    model.compile(loss=params['loss'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_phase = {\n",
    "    'kernel_size': 32,\n",
    "    'strides': 4,\n",
    "    'pool_size': 2,\n",
    "    'filters': 8,\n",
    "    'lstm_output_size': 236,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'dropout': 0.09,\n",
    "    'activation': 'relu',\n",
    "    'optimizer': 'Nadam',\n",
    "    'last_activation': 'sigmoid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_br_hb = {\n",
    "    'kernel_size': 2,\n",
    "    'strides': 1,\n",
    "    'pool_size': 1,\n",
    "    'filters': 2,\n",
    "    'lstm_output_size': 4,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'dropout': 0.09,\n",
    "    'activation': 'relu',\n",
    "    'optimizer': 'Nadam',\n",
    "    'last_activation': 'sigmoid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel_size': 4,\n",
    "    'filters': 2,\n",
    "    'strides': 2,\n",
    "    'pool_size': 2,\n",
    "    'dropout': 0.09,\n",
    "    'optimizer': 'Nadam',\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'activation': 'relu',\n",
    "    'last_activation': 'sigmoid',\n",
    "    'lstm_output_size': 256,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the autoencoders with the classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of 7 ; time elapsed: 0:00:00.008976\n",
      "iteration: 2 of 7 ; time elapsed: 0:36:29.165944\n",
      "iteration: 3 of 7 ; time elapsed: 1:22:22.883035\n",
      "iteration: 4 of 7 ; time elapsed: 2:17:20.406974\n",
      "iteration: 5 of 7 ; time elapsed: 3:07:58.224104\n",
      "Completed! Time elapsed: 4:08:35.281540\n"
     ]
    }
   ],
   "source": [
    "# set the variables in the dictionary\n",
    "accuracies['LSTM'] = {}\n",
    "accs = accuracies['LSTM']\n",
    "accs['phase'] = []\n",
    "accs['breathing'] = []\n",
    "accs['heartbeat'] = []\n",
    "accs['combined br hb'] = []\n",
    "accs['undercomplete'] = []\n",
    "accs['sparse'] = []\n",
    "accs['deep'] = []\n",
    "accs['contractive'] = []\n",
    "accs['test id'] = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # leave out person out validation\n",
    "    for i in range(5): ##### <--------------------------------- TODO: change to range(n)\n",
    "\n",
    "        # print current iteration and time elapsed from start\n",
    "        print(\"iteration:\", i+1, \"of\", n, \"; time elapsed:\", datetime.now()-start_time)\n",
    "\n",
    "        ## ----- Data preparation:\n",
    "        validation_idents = [idents[i]]\n",
    "        test_idents = [idents[i-1]]\n",
    "\n",
    "        train_idents = []\n",
    "        for ident in idents:\n",
    "            if (ident not in test_idents) and (ident not in validation_idents):\n",
    "                train_idents.append(ident)\n",
    "\n",
    "        # save test id to see which id yielded which accuracies\n",
    "        accs['test id'].append(test_idents[0])\n",
    "        \n",
    "        # Load data (xt-raw phase data, y-class, br-breathing data, hb-heartbeat data, cmb-combined [br,hb])\n",
    "        xt_train, y_train, br_train, hb_train, cmb_train = get_data_from_idents_br_hb(path, train_idents, seconds)\n",
    "        xt_valid, y_valid, br_valid, hb_valid, cmb_valid = get_data_from_idents_br_hb(path, validation_idents, seconds)\n",
    "        xt_test, y_test, br_test, hb_test, cmb_test = get_data_from_idents_br_hb(path, test_idents, seconds)\n",
    "\n",
    "        # Scale data with standard scaler then MinMax scaler\n",
    "        # Raw Phase data:\n",
    "        xt_train = scale_data(xt_train, standardScaler=True, minMaxScaler=True)\n",
    "        xt_valid = scale_data(xt_valid, standardScaler=True, minMaxScaler=True)\n",
    "        xt_test = scale_data(xt_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted breathing data:\n",
    "        br_train = scale_data(br_train, standardScaler=True, minMaxScaler=True)\n",
    "        br_valid = scale_data(br_valid, standardScaler=True, minMaxScaler=True)\n",
    "        br_test = scale_data(br_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Hand extracted Heartbeat data:\n",
    "        hb_train = scale_data(hb_train, standardScaler=True, minMaxScaler=True)\n",
    "        hb_valid = scale_data(hb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        hb_test = scale_data(hb_test, standardScaler=True, minMaxScaler=True)\n",
    "        # Combined breathing and heartbeat data (joined together into one matrix)\n",
    "        cmb_train = scale_data(cmb_train, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_valid = scale_data(cmb_valid, standardScaler=True, minMaxScaler=True)\n",
    "        cmb_test = scale_data(cmb_test, standardScaler=True, minMaxScaler=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## ----- Classify without autoencoders:\n",
    "        # Phase classifier:\n",
    "        model = LSTM_classifier_base(params_phase)\n",
    "        # reshape data for the classifier\n",
    "        xtt_train = xt_train.reshape(-1, xt_train[0].shape[0], 1)\n",
    "        xtt_valid = xt_valid.reshape(-1, xt_valid[0].shape[0], 1)\n",
    "        xtt_test = xt_test.reshape(-1, xt_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, xtt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xtt_valid, y_valid, xtt_test, y_test)\n",
    "        accs['phase'].append(curr_acc)\n",
    "\n",
    "        # Breathing classifier:\n",
    "        model = LSTM_classifier_base(params_br_hb)\n",
    "        # reshape data for the classifier\n",
    "        brt_train = br_train.reshape(-1, br_train[0].shape[0], 1)\n",
    "        brt_valid = br_valid.reshape(-1, br_valid[0].shape[0], 1)\n",
    "        brt_test = br_test.reshape(-1, br_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, brt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               brt_valid, y_valid, brt_test, y_test)\n",
    "        accs['breathing'].append(curr_acc)\n",
    "\n",
    "        # Heartbeat classifier:\n",
    "        model = LSTM_classifier_base(params_br_hb)\n",
    "        # reshape data for the classifier\n",
    "        hbt_train = hb_train.reshape(-1, hb_train[0].shape[0], 1)\n",
    "        hbt_valid = hb_valid.reshape(-1, hb_valid[0].shape[0], 1)\n",
    "        hbt_test = hb_test.reshape(-1, hb_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, hbt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               hbt_valid, y_valid, hbt_test, y_test)\n",
    "        accs['heartbeat'].append(curr_acc)\n",
    "\n",
    "        # Combined classifier:\n",
    "        model = LSTM_classifier_base(params_br_hb)\n",
    "        # reshape data for the classifier\n",
    "        cmbt_train = cmb_train.reshape(-1, cmb_train[0].shape[0], 1)\n",
    "        cmbt_valid = cmb_valid.reshape(-1, cmb_valid[0].shape[0], 1)\n",
    "        cmbt_test = cmb_test.reshape(-1, cmb_test[0].shape[0], 1)\n",
    "        # train and evaluate\n",
    "        sc, curr_acc, epoch_data = model_train(model, cmbt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               cmbt_valid, y_valid, cmbt_test, y_test)\n",
    "        accs['combined br hb'].append(curr_acc)\n",
    "\n",
    "        \n",
    "        \n",
    "        ## ----- Classify with autoencoders:\n",
    "        # AE Training params\n",
    "        batch_size = 256\n",
    "        epochs = 100\n",
    "        encoding_dim = 64\n",
    "\n",
    "        # undercomplete AE\n",
    "        autoencoder, encoded = undercomplete_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['undercomplete'].append(curr_acc)\n",
    "\n",
    "        # sparse AE\n",
    "        autoencoder, encoded = sparse_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['sparse'].append(curr_acc)\n",
    "\n",
    "        # deep AE\n",
    "        autoencoder, encoded = deep_ae(xt_train, enc_layers=[512,256], encoding_dim=encoding_dim, dec_layers=[256,512])\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['deep'].append(curr_acc)\n",
    "\n",
    "        # contractive AE\n",
    "        autoencoder, encoded = contractive_ae(xt_train, encoding_dim)\n",
    "        sc, curr_acc, epoch_data = model_train(autoencoder, xt_train, xt_train, batch_size, epochs,\n",
    "                                               xt_valid, xt_valid, xt_test, xt_test)\n",
    "        model = LSTM_classifier(encoded, params)\n",
    "        model = Model(inputs=autoencoder.inputs, outputs=model)\n",
    "        model.compile(loss=params['loss'],\n",
    "                      optimizer=params['optimizer'],\n",
    "                      metrics=metrics)\n",
    "        sc, curr_acc, epoch_data = model_train(model, xt_train, y_train, params['batch_size'], params['epochs'],\n",
    "                                               xt_valid, y_valid, xt_test, y_test)\n",
    "        accs['contractive'].append(curr_acc)\n",
    "\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Completed!\", \"Time elapsed:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>breathing</th>\n",
       "      <th>heartbeat</th>\n",
       "      <th>combined br hb</th>\n",
       "      <th>undercomplete</th>\n",
       "      <th>sparse</th>\n",
       "      <th>deep</th>\n",
       "      <th>contractive</th>\n",
       "      <th>test id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62i9y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2gu87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>iz2ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>1mpau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>7dwjy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse  \\\n",
       "0  0.450000   0.500000   0.625000        0.658333       0.475000  0.383333   \n",
       "1  0.591667   0.641667   0.541667        0.566667       0.633333  0.566667   \n",
       "2  0.616667   0.433333   0.441667        0.466667       0.500000  0.475000   \n",
       "3  0.258333   0.458333   0.491667        0.466667       0.591667  0.575000   \n",
       "4  0.583333   0.416667   0.500000        0.500000       0.516667  0.500000   \n",
       "\n",
       "       deep  contractive test id  \n",
       "0  0.541667     0.533333   62i9y  \n",
       "1  0.641667     0.566667   2gu87  \n",
       "2  0.583333     0.525000   iz2ps  \n",
       "3  0.525000     0.508333   1mpau  \n",
       "4  0.425000     0.483333   7dwjy  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracies of each method and corresponding id which yielded that accuracy (same row)\n",
    "pandas.DataFrame.from_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.258333   0.416667   0.441667        0.466667       0.475000  0.383333  0.425000     0.483333\n",
      "max     0.616667   0.641667   0.625000        0.658333       0.633333  0.575000  0.641667     0.566667\n",
      "mean    0.500000   0.490000   0.520000        0.531667       0.543333  0.500000  0.543333     0.523333\n",
      "median  0.583333   0.458333   0.500000        0.500000       0.516667  0.500000  0.541667     0.525000\n"
     ]
    }
   ],
   "source": [
    "# print some statistics for each method\n",
    "print_accs_stats(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compare Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print min, max, mean, median for each clasifier/autoencoder combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- kNN: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.391667   0.400000   0.458333        0.416667       0.508333  0.391667  0.416667     0.433333\n",
      "max     0.700000   0.608333   0.583333        0.683333       0.683333  0.608333  0.641667     0.691667\n",
      "mean    0.554762   0.503571   0.544048        0.503571       0.558333  0.495238  0.528571     0.535714\n",
      "median  0.558333   0.541667   0.575000        0.475000       0.541667  0.491667  0.516667     0.525000\n",
      "\n",
      "\n",
      "----------- SVC: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.300000   0.308333   0.441667        0.408333       0.416667  0.483333  0.375000     0.433333\n",
      "max     0.616667   0.650000   0.516667        0.633333       0.625000  0.625000  0.616667     0.691667\n",
      "mean    0.498810   0.495238   0.494048        0.498810       0.505952  0.521429  0.521429     0.536905\n",
      "median  0.533333   0.491667   0.500000        0.500000       0.500000  0.491667  0.516667     0.533333\n",
      "\n",
      "\n",
      "----------- random_forest: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.350000   0.325000   0.375000        0.208333       0.300000  0.391667  0.333333     0.325000\n",
      "max     0.625000   0.700000   0.558333        0.600000       0.633333  0.541667  0.558333     0.566667\n",
      "mean    0.447619   0.501190   0.466667        0.494048       0.459524  0.480952  0.467857     0.455952\n",
      "median  0.400000   0.483333   0.466667        0.575000       0.441667  0.466667  0.508333     0.450000\n",
      "\n",
      "\n",
      "----------- naive_bayesian: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.475000   0.150000   0.358333        0.225000       0.416667  0.391667  0.416667     0.375000\n",
      "max     0.725000   0.633333   0.600000        0.616667       0.700000  0.725000  0.750000     0.733333\n",
      "mean    0.578571   0.432143   0.494048        0.438095       0.551190  0.526190  0.546429     0.513095\n",
      "median  0.566667   0.466667   0.500000        0.466667       0.566667  0.541667  0.516667     0.500000\n",
      "\n",
      "\n",
      "----------- XGBoost: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.383333   0.400000   0.391667        0.125000       0.383333  0.325000  0.416667     0.375000\n",
      "max     0.533333   0.650000   0.550000        0.616667       0.583333  0.591667  0.616667     0.625000\n",
      "mean    0.464286   0.532143   0.490476        0.464286       0.478571  0.475000  0.509524     0.470238\n",
      "median  0.450000   0.558333   0.500000        0.500000       0.475000  0.500000  0.491667     0.425000\n",
      "\n",
      "\n",
      "----------- simple_dense: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.408333   0.225000   0.391667        0.366667       0.441667  0.358333  0.300000     0.483333\n",
      "max     0.641667   0.658333   0.558333        0.616667       0.625000  0.650000  0.658333     0.666667\n",
      "mean    0.513095   0.451190   0.497619        0.489286       0.539286  0.504762  0.533333     0.555952\n",
      "median  0.500000   0.525000   0.500000        0.466667       0.516667  0.475000  0.558333     0.550000\n",
      "\n",
      "\n",
      "----------- LSTM: -----------\n",
      "           phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive\n",
      "min     0.258333   0.416667   0.441667        0.466667       0.475000  0.383333  0.425000     0.483333\n",
      "max     0.616667   0.641667   0.625000        0.658333       0.633333  0.575000  0.641667     0.566667\n",
      "mean    0.500000   0.490000   0.520000        0.531667       0.543333  0.500000  0.543333     0.523333\n",
      "median  0.583333   0.458333   0.500000        0.500000       0.516667  0.500000  0.541667     0.525000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(\"-----------\", classifier + \":\", \"-----------\")\n",
    "    accs = accuracies[classifier]\n",
    "    print_accs_stats(accs)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all accuracies in table form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.458333   0.408333   0.575000        0.525000       0.550000  0.391667  0.475000     0.525000   62i9y\n",
      "1  0.658333   0.400000   0.583333        0.458333       0.541667  0.525000  0.575000     0.558333   2gu87\n",
      "2  0.575000   0.441667   0.583333        0.475000       0.558333  0.466667  0.516667     0.583333   iz2ps\n",
      "3  0.541667   0.608333   0.491667        0.541667       0.541667  0.508333  0.466667     0.483333   1mpau\n",
      "4  0.558333   0.550000   0.541667        0.683333       0.525000  0.491667  0.416667     0.433333   7dwjy\n",
      "5  0.391667   0.541667   0.575000        0.425000       0.508333  0.475000  0.641667     0.475000   7swyk\n",
      "6  0.700000   0.575000   0.458333        0.416667       0.683333  0.608333  0.608333     0.691667   94mnx\n",
      "\n",
      "\n",
      "SVC:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.300000   0.491667   0.500000        0.441667       0.416667  0.491667  0.375000     0.466667   62i9y\n",
      "1  0.433333   0.450000   0.516667        0.516667       0.508333  0.491667  0.508333     0.541667   2gu87\n",
      "2  0.533333   0.308333   0.500000        0.408333       0.500000  0.483333  0.550000     0.558333   iz2ps\n",
      "3  0.616667   0.516667   0.500000        0.458333       0.483333  0.516667  0.516667     0.533333   1mpau\n",
      "4  0.475000   0.441667   0.500000        0.533333       0.425000  0.491667  0.466667     0.433333   7dwjy\n",
      "5  0.558333   0.608333   0.500000        0.500000       0.583333  0.550000  0.616667     0.533333   7swyk\n",
      "6  0.575000   0.650000   0.441667        0.633333       0.625000  0.625000  0.616667     0.691667   94mnx\n",
      "\n",
      "\n",
      "random_forest:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.391667   0.450000   0.491667        0.441667       0.300000  0.391667  0.333333     0.325000   62i9y\n",
      "1  0.400000   0.483333   0.433333        0.591667       0.416667  0.450000  0.508333     0.383333   2gu87\n",
      "2  0.350000   0.525000   0.425000        0.600000       0.441667  0.466667  0.533333     0.550000   iz2ps\n",
      "3  0.500000   0.325000   0.375000        0.208333       0.458333  0.533333  0.466667     0.466667   1mpau\n",
      "4  0.350000   0.700000   0.466667        0.575000       0.408333  0.541667  0.358333     0.450000   7dwjy\n",
      "5  0.625000   0.450000   0.516667        0.575000       0.633333  0.458333  0.516667     0.450000   7swyk\n",
      "6  0.516667   0.575000   0.558333        0.466667       0.558333  0.525000  0.558333     0.566667   94mnx\n",
      "\n",
      "\n",
      "naive_bayesian:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.475000   0.558333   0.491667        0.500000       0.416667  0.391667  0.466667     0.375000   62i9y\n",
      "1  0.600000   0.633333   0.600000        0.616667       0.566667  0.633333  0.608333     0.533333   2gu87\n",
      "2  0.516667   0.358333   0.425000        0.375000       0.600000  0.541667  0.516667     0.500000   iz2ps\n",
      "3  0.641667   0.150000   0.541667        0.225000       0.450000  0.433333  0.550000     0.491667   1mpau\n",
      "4  0.566667   0.466667   0.358333        0.466667       0.558333  0.416667  0.516667     0.541667   7dwjy\n",
      "5  0.525000   0.383333   0.500000        0.400000       0.566667  0.541667  0.416667     0.416667   7swyk\n",
      "6  0.725000   0.475000   0.541667        0.483333       0.700000  0.725000  0.750000     0.733333   94mnx\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.383333   0.558333   0.458333        0.500000       0.383333  0.325000  0.575000     0.375000   62i9y\n",
      "1  0.450000   0.558333   0.541667        0.583333       0.408333  0.416667  0.491667     0.483333   2gu87\n",
      "2  0.416667   0.408333   0.550000        0.491667       0.541667  0.500000  0.475000     0.425000   iz2ps\n",
      "3  0.516667   0.400000   0.441667        0.125000       0.475000  0.500000  0.483333     0.550000   1mpau\n",
      "4  0.416667   0.650000   0.500000        0.408333       0.408333  0.425000  0.416667     0.408333   7dwjy\n",
      "5  0.533333   0.516667   0.550000        0.525000       0.550000  0.591667  0.616667     0.425000   7swyk\n",
      "6  0.533333   0.633333   0.391667        0.616667       0.583333  0.566667  0.508333     0.625000   94mnx\n",
      "\n",
      "\n",
      "simple_dense:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.425000   0.625000   0.500000        0.516667       0.516667  0.466667  0.300000     0.525000   62i9y\n",
      "1  0.641667   0.658333   0.541667        0.616667       0.516667  0.541667  0.616667     0.591667   2gu87\n",
      "2  0.500000   0.316667   0.391667        0.433333       0.483333  0.475000  0.541667     0.483333   iz2ps\n",
      "3  0.408333   0.225000   0.491667        0.458333       0.583333  0.608333  0.558333     0.575000   1mpau\n",
      "4  0.558333   0.525000   0.500000        0.466667       0.625000  0.433333  0.583333     0.550000   7dwjy\n",
      "5  0.425000   0.241667   0.558333        0.366667       0.441667  0.358333  0.475000     0.500000   7swyk\n",
      "6  0.633333   0.566667   0.500000        0.566667       0.608333  0.650000  0.658333     0.666667   94mnx\n",
      "\n",
      "\n",
      "LSTM:\n",
      "      phase  breathing  heartbeat  combined br hb  undercomplete    sparse      deep  contractive test id\n",
      "0  0.450000   0.500000   0.625000        0.658333       0.475000  0.383333  0.541667     0.533333   62i9y\n",
      "1  0.591667   0.641667   0.541667        0.566667       0.633333  0.566667  0.641667     0.566667   2gu87\n",
      "2  0.616667   0.433333   0.441667        0.466667       0.500000  0.475000  0.583333     0.525000   iz2ps\n",
      "3  0.258333   0.458333   0.491667        0.466667       0.591667  0.575000  0.525000     0.508333   1mpau\n",
      "4  0.583333   0.416667   0.500000        0.500000       0.516667  0.500000  0.425000     0.483333   7dwjy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(classifier + \":\")\n",
    "#     print(pandas.DataFrame.from_dict(accuracies[classifier]))\n",
    "    # Using .to_string() gives nicer loooking results (doesn't split into new line)\n",
    "    print(pandas.DataFrame.from_dict(accuracies[classifier]).to_string())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37talos",
   "language": "python",
   "name": "py37talos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
